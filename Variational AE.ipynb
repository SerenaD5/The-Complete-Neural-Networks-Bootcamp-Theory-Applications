{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vo_U5DmHZhEI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M43mAJb5ZhEJ",
        "outputId": "8cc93698-f5e9-4786-a092-e5e95fce782c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 496kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.86MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.84MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "image_size = 784  # 输入图像的大小，28x28像素展平为784\n",
        "hidden_dim = 400  # 隐藏层的维度\n",
        "latent_dim = 20   # 潜在空间的维度\n",
        "batch_size = 128  # 每个批次的样本数量\n",
        "epochs = 10       # 训练的轮数\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "# Create directory to save the reconstructed and sampled images (if directory not present)\n",
        "sample_dir = 'results'\n",
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykjEK-YXZhEJ"
      },
      "source": [
        "![vae](https://user-images.githubusercontent.com/30661597/78418103-a2047200-766b-11ea-8205-c7e5712715f4.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "se3LpKKFZhEK"
      },
      "outputs": [],
      "source": [
        "# # Define hyperparameters\n",
        "# image_size = 784\n",
        "# hidden_dim = 400\n",
        "# latent_dim = 20\n",
        "# batch_size = 128\n",
        "# epochs = 10\n",
        "\n",
        "# VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        初始化VAE模型，包括定义各层的结构。\n",
        "        \"\"\"\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(image_size, hidden_dim) # 输入层到隐藏层的全连接层\n",
        "        self.fc2_mean = nn.Linear(hidden_dim, latent_dim)  # 隐藏层到潜在空间均值的全连接层\n",
        "        self.fc2_logvar = nn.Linear(hidden_dim, latent_dim)  # 隐藏层到潜在空间对数方差的全连接层\n",
        "        self.fc3 = nn.Linear(latent_dim, hidden_dim)  # 潜在空间到隐藏层的全连接层\n",
        "        self.fc4 = nn.Linear(hidden_dim, image_size) # 隐藏层到输出层的全连接层\n",
        "\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        编码输入数据，返回潜在空间的均值和对数方差。\n",
        "        \"\"\"\n",
        "        h = F.relu(self.fc1(x))  # 输入层到隐藏层的激活函数\n",
        "        mu = self.fc2_mean(h)   # 计算潜在空间的均值\n",
        "        log_var = self.fc2_logvar(h) # 计算潜在空间的对数方差\n",
        "        return mu, log_var\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        \"\"\"\n",
        "        重新参数化技巧，将均值和对数方差转换为潜在变量。\n",
        "        \"\"\"\n",
        "        std = torch.exp(logvar/2) # 计算标准差, if use *0.5 is better\n",
        "        eps = torch.randn_like(std)  # 生成与标准差形状相同的标准正态分布噪声\n",
        "        return mu + eps * std # 重新参数化技巧 返回值：通过均值和噪声乘以标准差相加得到重新参数化的潜在变量\n",
        "\n",
        "    def decode(self, z):\n",
        "        \"\"\"\n",
        "        解码潜在变量，返回重建的输出。\n",
        "        \"\"\"\n",
        "        h = F.relu(self.fc3(z)) # 潜在空间到隐藏层的激活函数\n",
        "        out = torch.sigmoid(self.fc4(h))  # 隐藏层到输出层的激活函数\n",
        "                                          #为什么它是 S 型激活函数？因为记住，我们已经将这些值标准化了介于零至一之间。现在我们有点幸运因为 MS 数据集已经介于 0 和 1 之间，所以我们不需要手动执行规范化。由于值介于 0 和 1 之间，这意味着输出也应该是\n",
        "                                        #介于零和一之间。如何将输出压缩到 0 和 1 之间是使用 S 型函数。这就是我们使用 S 型激活函数的原因\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        前向传播，返回重建的输出、潜在空间的均值和对数方差。\n",
        "        \"\"\"\n",
        "        # x: (batch_size, 1, 28,28) --> (batch_size, 784)\n",
        "        mu, logvar = self.encode(x.view(-1, image_size))# 编码阶段 x：输入数据，形状为(batch_size, 1, 28, 28)，通过view方法展平成(batch_size, 784)\n",
        "        z = self.reparameterize(mu, logvar)  # 重新参数化\n",
        "        reconstructed = self.decode(z)  # 解码阶段\n",
        "        return reconstructed, mu, logvar\n",
        "\n",
        "# Define model and optimizer\n",
        "model = VAE().to(device) # 将模型移动到指定设备（如GPU）\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # 使用Adam优化器"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 参数详细解释\n",
        "\n",
        "#### `nn.Linear(in_features, out_features)`\n",
        "- `in_features`：输入特征的数量，数据类型为整数。例如，`image_size`为784。\n",
        "- `out_features`：输出特征的数量，数据类型为整数。例如，`hidden_dim`为400。\n",
        "\n",
        "#### `F.relu(input)`\n",
        "- `input`：输入张量，数据类型为`torch.Tensor`。应用ReLU激活函数。\n",
        "\n",
        "#### `torch.exp(input)`\n",
        "- `input`：输入张量，数据类型为`torch.Tensor`。计算输入张量的指数。\n",
        "\n",
        "#### `torch.randn_like(input)`\n",
        "- `input`：输入张量，数据类型为`torch.Tensor`。生成与输入张量形状相同的标准正态分布噪声。\n",
        "\n",
        "#### `torch.sigmoid(input)`\n",
        "- `input`：输入张量，数据类型为`torch.Tensor`。应用Sigmoid激活函数。\n",
        "\n",
        "### 函数选择分析\n",
        "\n",
        "#### `nn.Linear`\n",
        "- 选择原因：全连接层是实现线性变换的基本构建块，适用于VAE模型的编码和解码过程。\n",
        "- 替代方案：可以使用卷积层（`nn.Conv2d`）来处理图像数据，但需要调整模型结构。\n",
        "\n",
        "#### `F.relu`\n",
        "- 选择原因：ReLU激活函数能够有效缓解梯度消失问题，适用于深度神经网络。\n",
        "- 替代方案：可以使用其他激活函数，如Leaky ReLU或ELU，根据具体任务需求选择。\n",
        "\n",
        "#### `torch.exp`\n",
        "- 选择原因：计算标准差时需要对数方差取指数。\n",
        "- 替代方案：无直接替代方案。\n",
        "\n",
        "#### `torch.randn_like`\n",
        "- 选择原因：生成与标准差形状相同的标准正态分布噪声，用于重新参数化。\n",
        "- 替代方案：可以使用`torch.randn`并手动调整形状，但`torch.randn_like`更简洁。\n",
        "\n",
        "#### `torch.sigmoid`\n",
        "- 选择原因：Sigmoid激活函数将输出限制在[0, 1]范围内，适用于重建图像的像素值。\n",
        "- 替代方案：可以使用Tanh激活函数，但需要对输出进行适当的缩放和偏移。\n",
        "\n",
        "### 专门分析领域\n",
        "\n",
        "#### 激活函数\n",
        "- ReLU：计算简单，缓解梯度消失问题，但可能导致神经元死亡。\n",
        "- Sigmoid：输出范围在[0, 1]，适用于概率输出，但可能导致梯度消失。\n",
        "- Tanh：输出范围在[-1, 1]，适用于中心化数据，但可能导致梯度消失。\n",
        "\n",
        "#### 数据处理函数\n",
        "- `view`：展平输入数据，适用于将图像数据转换为一维向量。\n",
        "- `exp`：计算指数，用于从对数方差计算标准差。\n",
        "- `randn_like`：生成标准正态分布噪声，用于重新参数化。"
      ],
      "metadata": {
        "id": "l7m-9_62pZlH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF3rxWfoZhEK"
      },
      "source": [
        "$Loss = -E[\\log P(X | z)]+D_{K L}[N(\\mu(X), \\Sigma(X)) \\| N(0,1)]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXvy-QDWZhEK"
      },
      "source": [
        "#### $D_{K L}[N(\\mu(X), \\Sigma(X)) \\| N(0,1)]=\\frac{1}{2} \\sum_{k}\\left(\\exp (\\Sigma(X))+\\mu^{2}(X)-1-\\Sigma(X)\\right)$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kZCpGNi7ZhEK"
      },
      "outputs": [],
      "source": [
        "# Define Loss\n",
        "def loss_function(reconstructed_image, original_image, mu, logvar):\n",
        "    bce = F.binary_cross_entropy(reconstructed_image, original_image.view(-1, 784), reduction = 'sum')\n",
        "    # kld = torch.sum(0.5 * torch.sum(logvar.exp() + mu.pow(2) - 1 - logvar, 1))\n",
        "    kld = 0.5 * torch.sum(logvar.exp() + mu.pow(2) - 1 - logvar)\n",
        "    #############################################################\n",
        "    # logvar, exp: (batch_size,20)\n",
        "    # kld = 0.5 * torch.sum(logvar.exp() + mu.pow(2) - 1 - logvar,1) #(batch_size)\n",
        "    # kld_sum = torch.sum(kld)\n",
        "    #############################################################\n",
        "    return bce + kld\n",
        "\n",
        "\n",
        "# Train function\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        reconstructed, mu, logvar = model(images)\n",
        "        loss = loss_function(reconstructed, images, mu, logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(\"Train Epoch {} [Batch {}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), loss.item()/len(images)))\n",
        "\n",
        "    print('=====> Epoch {}, Average Loss: {:.3f}'.format(epoch, train_loss/len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "# Test function\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            reconstructed, mu, logvar = model(images)\n",
        "            test_loss += loss_function(reconstructed, images, mu, logvar).item()\n",
        "            if batch_idx == 0:\n",
        "                comparison = torch.cat([images[:5], reconstructed.view(batch_size, 1, 28, 28)[:5]])\n",
        "                save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow = 5)\n",
        "\n",
        "    print('=====> Average Test Loss: {:.3f}'.format(test_loss/len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 代码逐行解释\n",
        "\n",
        "```python\n",
        "# 定义损失函数\n",
        "def loss_function(reconstructed_image, original_image, mu, logvar):\n",
        "    bce = F.binary_cross_entropy(reconstructed_image, original_image.view(-1, 784), reduction='sum')\n",
        "    kld = 0.5 * torch.sum(logvar.exp() + mu.pow(2) - 1 - logvar)\n",
        "    return bce + kld\n",
        "```\n",
        "这段代码定义了VAE的损失函数，包括重构误差和KL散度：\n",
        "- `reconstructed_image`：重建的图像，形状为`(batch_size, 784)`。\n",
        "- `original_image`：原始图像，形状为`(batch_size, 1, 28, 28)`，通过`view`方法展平成`(batch_size, 784)`。\n",
        "- `mu`：潜在空间的均值。\n",
        "- `logvar`：潜在空间的对数方差。\n",
        "- `bce`：二元交叉熵损失，用于衡量重建图像与原始图像之间的差异。\n",
        "- `kld`：KL散度，用于衡量潜在空间分布与标准正态分布之间的差异。\n",
        "- 返回值：总损失，即二元交叉熵损失和KL散度的和。\n",
        "\n",
        "```python\n",
        "# 训练函数\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for i, (images, _) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        reconstructed, mu, logvar = model(images)\n",
        "        loss = loss_function(reconstructed, images, mu, logvar)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(\"Train Epoch {} [Batch {}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), loss.item()/len(images)))\n",
        "            \n",
        "    print('=====> Epoch {}, Average Loss: {:.3f}'.format(epoch, train_loss/len(train_loader.dataset)))\n",
        "```\n",
        "`train`函数定义了模型的训练过程：\n",
        "- `epoch`：当前训练的轮数。\n",
        "- `model.train()`：将模型设置为训练模式。\n",
        "- `train_loss`：累计训练损失。\n",
        "- `for i, (images, _) in enumerate(train_loader)`：遍历训练数据集。\n",
        "  - `images`：输入图像。\n",
        "  - `images.to(device)`：将图像移动到指定设备（如GPU）。\n",
        "  - `reconstructed, mu, logvar`：通过模型前向传播得到重建图像、潜在空间的均值和对数方差。\n",
        "  - `loss`：计算损失。\n",
        "  - `optimizer.zero_grad()`：清零梯度。\n",
        "  - `loss.backward()`：反向传播计算梯度。\n",
        "  - `train_loss += loss.item()`：累计损失。\n",
        "  - `optimizer.step()`：更新模型参数。\n",
        "  - `if i % 100 == 0`：每100个批次打印一次训练信息。\n",
        "- `print('=====> Epoch {}, Average Loss: {:.3f}'.format(epoch, train_loss/len(train_loader.dataset)))`：打印每个轮次的平均损失。\n",
        "\n",
        "```python\n",
        "# 测试函数\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, _) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "            reconstructed, mu, logvar = model(images)\n",
        "            test_loss += loss_function(reconstructed, images, mu, logvar).item()\n",
        "            if batch_idx == 0:\n",
        "                comparison = torch.cat([images[:5], reconstructed.view(batch_size, 1, 28, 28)[:5]])\n",
        "                save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow=5)\n",
        "\n",
        "    print('=====> Average Test Loss: {:.3f}'.format(test_loss/len(test_loader.dataset)))\n",
        "```\n",
        "`test`函数定义了模型的测试过程：\n",
        "- `epoch`：当前测试的轮数。\n",
        "- `model.eval()`：将模型设置为评估模式。\n",
        "- `test_loss`：累计测试损失。\n",
        "- `with torch.no_grad()`：在不计算梯度的上下文中进行测试。\n",
        "  - `for batch_idx, (images, _) in enumerate(test_loader)`：遍历测试数据集。\n",
        "    - `images`：输入图像。\n",
        "    - `images.to(device)`：将图像移动到指定设备（如GPU）。\n",
        "    - `reconstructed, mu, logvar`：通过模型前向传播得到重建图像、潜在空间的均值和对数方差。\n",
        "    - `test_loss += loss_function(reconstructed, images, mu, logvar).item()`：累计损失。\n",
        "    - `if batch_idx == 0`：在第一个批次时保存重建图像。\n",
        "      - `comparison`：将原始图像和重建图像拼接在一起。\n",
        "      - `save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow=5)`：保存重建图像。\n",
        "- `print('=====> Average Test Loss: {:.3f}'.format(test_loss/len(test_loader.dataset)))`：打印平均测试损失。\n",
        "\n",
        "### 参数详细解释\n",
        "\n",
        "#### `loss_function(reconstructed_image, original_image, mu, logvar)`\n",
        "- `reconstructed_image`：重建的图像，形状为`(batch_size, 784)`。\n",
        "- `original_image`：原始图像，形状为`(batch_size, 1, 28, 28)`，通过`view`方法展平成`(batch_size, 784)`。\n",
        "- `mu`：潜在空间的均值。\n",
        "- `logvar`：潜在空间的对数方差。\n",
        "\n",
        "#### `train(epoch)`\n",
        "- `epoch`：当前训练的轮数，数据类型为整数。\n",
        "\n",
        "#### `test(epoch)`\n",
        "- `epoch`：当前测试的轮数，数据类型为整数。\n",
        "\n",
        "### 函数选择分析\n",
        "\n",
        "#### `F.binary_cross_entropy`\n",
        "- 选择原因：二元交叉熵损失适用于二分类任务，能够衡量重建图像与原始图像之间的差异。\n",
        "- 替代方案：可以使用均方误差（MSE）损失，但二元交叉熵在处理二值图像时效果更好。\n",
        "\n",
        "#### `torch.sum`\n",
        "- 选择原因：计算张量的和，用于计算KL散度。\n",
        "- 替代方案：无直接替代方案。\n",
        "\n",
        "#### `torch.no_grad`\n",
        "- 选择原因：在测试过程中不需要计算梯度，能够节省内存和计算资源。\n",
        "- 替代方案：无直接替代方案。\n",
        "\n",
        "#### `torch.cat`\n",
        "- 选择原因：拼接张量，用于将原始图像和重建图像拼接在一起。\n",
        "- 替代方案：可以使用`torch.stack`，但`torch.cat`更适合拼接操作。\n",
        "\n",
        "#### `save_image`\n",
        "- 选择原因：保存图像，用于可视化重建效果。\n",
        "- 替代方案：可以使用`matplotlib`等库进行图像保存，但`save_image`更简洁。\n",
        "\n",
        "### 专门分析领域\n",
        "\n",
        "#### 损失函数\n",
        "- 二元交叉熵：适用于二分类任务，能够衡量重建图像与原始图像之间的差异。\n",
        "- KL散度：衡量潜在空间分布与标准正态分布之间的差异，确保潜在空间的连续性和可解释性。\n",
        "\n",
        "#### 数据处理函数\n",
        "- `view`：展平输入数据，适用于将图像数据转换为一维向量。\n",
        "- `exp`：计算指数，用于从对数方差计算标准差。\n",
        "- `randn_like`：生成标准正态分布噪声，用于重新参数化。\n",
        "- `cat`：拼接张量，用于将原始图像和重建图像拼接在一起。\n",
        "\n",
        "### 参数特定指导\n",
        "\n",
        "#### 常见配置错误\n",
        "- `reduction='sum'`：确保二元交叉熵损失的归约方式为求和，而不是默认的求平均。\n",
        "- `view`：确保展平操作后的形状正确，避免维度错误。\n",
        "\n",
        "#### 参数调优策略\n",
        "- 根据数据集和任务需求调整损失函数的权重比例。\n",
        "- 选择合适的激活函数，避免梯度消失或神经元死亡。\n",
        "\n",
        "#### 输入验证建议\n",
        "- 确保输入数据的形状和类型正确，避免维度错误。\n",
        "- 在训练前对输入数据进行归一化或标准化处理，提高模型性能。\n",
        "\n",
        "### 建设性技术反馈\n",
        "\n",
        "1. **添加文档字符串**：\n",
        "   ```python\n",
        "   def loss_function(reconstructed_image, original_image, mu, logvar):\n",
        "       \"\"\"\n",
        "       计算VAE的损失函数，包括重构误差和KL散度。\n",
        "       \"\"\"\n",
        "       bce = F.binary_cross_entropy(reconstructed_image, original_image.view(-1, 784), reduction='sum')\n",
        "       kld = 0.5 * torch.sum(logvar.exp() + mu.pow(2) - 1 - logvar)\n",
        "       return bce + kld\n",
        "   ```\n",
        "\n",
        "2. **优化`train`和`test`函数**：\n",
        "   ```python\n",
        "   def train(epoch):\n",
        "       \"\"\"\n",
        "       训练VAE模型一个轮次。\n",
        "       \"\"\"\n",
        "       model.train()\n",
        "       train_loss = 0\n",
        "       for i, (images, _) in enumerate(train_loader):\n",
        "           images = images.to(device)\n",
        "           reconstructed, mu, logvar = model(images)\n",
        "           loss = loss_function(reconstructed, images, mu, logvar)\n",
        "           optimizer.zero_grad()\n",
        "           loss.backward()\n",
        "           train_loss += loss.item()\n",
        "           optimizer.step()\n",
        "           \n",
        "           if i % 100 == 0:\n",
        "               print(\"Train Epoch {} [Batch {}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), loss.item()/len(images)))\n",
        "               \n",
        "       print('=====> Epoch {}, Average Loss: {:.3f}'.format(epoch, train_loss/len(train_loader.dataset)))\n",
        "\n",
        "   def test(epoch):\n",
        "       \"\"\"\n",
        "       测试VAE模型一个轮次。\n",
        "       \"\"\"\n",
        "       model.eval()\n",
        "       test_loss = 0\n",
        "       with torch.no_grad():\n",
        "           for batch_idx, (images, _) in enumerate(test_loader):\n",
        "               images = images.to(device)\n",
        "               reconstructed, mu, logvar = model(images)\n",
        "               test_loss += loss_function(reconstructed, images, mu, logvar).item()\n",
        "               if batch_idx == 0:\n",
        "                   comparison = torch.cat([images[:5], reconstructed.view(batch_size, 1, 28, 28)[:5]])\n",
        "                   save_image(comparison.cpu(), 'results/reconstruction_' + str(epoch) + '.png', nrow=5)\n",
        "\n",
        "       print('=====> Average Test Loss: {:.3f}'.format(test_loss/len(test_loader.dataset)))\n",
        "   ```\n",
        "\n",
        "### 总结\n",
        "\n",
        "总体而言，代码结构清晰，逻辑正确，符合编码标准。通过添加文档字符串和优化部分计算，可以进一步提高代码的可读性和性能。"
      ],
      "metadata": {
        "id": "iRZRhbgGEqEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vcvKuPaBZhEL",
        "outputId": "0e279da9-9ec4-4097-dc2d-7a123b239ad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch 1 [Batch 0/469]\tLoss: 547.777\n",
            "Train Epoch 1 [Batch 100/469]\tLoss: 185.191\n",
            "Train Epoch 1 [Batch 200/469]\tLoss: 149.519\n",
            "Train Epoch 1 [Batch 300/469]\tLoss: 136.740\n",
            "Train Epoch 1 [Batch 400/469]\tLoss: 129.916\n",
            "=====> Epoch 1, Average Loss: 163.632\n",
            "=====> Average Test Loss: 127.133\n",
            "Train Epoch 2 [Batch 0/469]\tLoss: 128.528\n",
            "Train Epoch 2 [Batch 100/469]\tLoss: 119.314\n",
            "Train Epoch 2 [Batch 200/469]\tLoss: 122.078\n",
            "Train Epoch 2 [Batch 300/469]\tLoss: 115.897\n",
            "Train Epoch 2 [Batch 400/469]\tLoss: 117.829\n",
            "=====> Epoch 2, Average Loss: 120.994\n",
            "=====> Average Test Loss: 115.292\n",
            "Train Epoch 3 [Batch 0/469]\tLoss: 114.449\n",
            "Train Epoch 3 [Batch 100/469]\tLoss: 114.248\n",
            "Train Epoch 3 [Batch 200/469]\tLoss: 115.108\n",
            "Train Epoch 3 [Batch 300/469]\tLoss: 114.157\n",
            "Train Epoch 3 [Batch 400/469]\tLoss: 114.876\n",
            "=====> Epoch 3, Average Loss: 114.260\n",
            "=====> Average Test Loss: 111.749\n",
            "Train Epoch 4 [Batch 0/469]\tLoss: 110.425\n",
            "Train Epoch 4 [Batch 100/469]\tLoss: 115.169\n",
            "Train Epoch 4 [Batch 200/469]\tLoss: 110.252\n",
            "Train Epoch 4 [Batch 300/469]\tLoss: 115.144\n",
            "Train Epoch 4 [Batch 400/469]\tLoss: 112.603\n",
            "=====> Epoch 4, Average Loss: 111.461\n",
            "=====> Average Test Loss: 109.676\n",
            "Train Epoch 5 [Batch 0/469]\tLoss: 109.917\n",
            "Train Epoch 5 [Batch 100/469]\tLoss: 107.882\n",
            "Train Epoch 5 [Batch 200/469]\tLoss: 113.978\n",
            "Train Epoch 5 [Batch 300/469]\tLoss: 107.417\n",
            "Train Epoch 5 [Batch 400/469]\tLoss: 109.921\n",
            "=====> Epoch 5, Average Loss: 109.782\n",
            "=====> Average Test Loss: 108.502\n",
            "Train Epoch 6 [Batch 0/469]\tLoss: 111.964\n",
            "Train Epoch 6 [Batch 100/469]\tLoss: 109.169\n",
            "Train Epoch 6 [Batch 200/469]\tLoss: 109.821\n",
            "Train Epoch 6 [Batch 300/469]\tLoss: 109.730\n",
            "Train Epoch 6 [Batch 400/469]\tLoss: 110.705\n",
            "=====> Epoch 6, Average Loss: 108.632\n",
            "=====> Average Test Loss: 107.528\n",
            "Train Epoch 7 [Batch 0/469]\tLoss: 108.266\n",
            "Train Epoch 7 [Batch 100/469]\tLoss: 106.377\n",
            "Train Epoch 7 [Batch 200/469]\tLoss: 105.193\n",
            "Train Epoch 7 [Batch 300/469]\tLoss: 105.183\n",
            "Train Epoch 7 [Batch 400/469]\tLoss: 108.438\n",
            "=====> Epoch 7, Average Loss: 107.796\n",
            "=====> Average Test Loss: 107.158\n",
            "Train Epoch 8 [Batch 0/469]\tLoss: 109.193\n",
            "Train Epoch 8 [Batch 100/469]\tLoss: 106.405\n",
            "Train Epoch 8 [Batch 200/469]\tLoss: 106.209\n",
            "Train Epoch 8 [Batch 300/469]\tLoss: 110.001\n",
            "Train Epoch 8 [Batch 400/469]\tLoss: 106.891\n",
            "=====> Epoch 8, Average Loss: 107.144\n",
            "=====> Average Test Loss: 106.231\n",
            "Train Epoch 9 [Batch 0/469]\tLoss: 109.222\n",
            "Train Epoch 9 [Batch 100/469]\tLoss: 105.536\n",
            "Train Epoch 9 [Batch 200/469]\tLoss: 106.948\n",
            "Train Epoch 9 [Batch 300/469]\tLoss: 106.639\n",
            "Train Epoch 9 [Batch 400/469]\tLoss: 105.060\n",
            "=====> Epoch 9, Average Loss: 106.696\n",
            "=====> Average Test Loss: 106.178\n",
            "Train Epoch 10 [Batch 0/469]\tLoss: 107.175\n",
            "Train Epoch 10 [Batch 100/469]\tLoss: 107.395\n",
            "Train Epoch 10 [Batch 200/469]\tLoss: 110.038\n",
            "Train Epoch 10 [Batch 300/469]\tLoss: 108.061\n",
            "Train Epoch 10 [Batch 400/469]\tLoss: 107.067\n",
            "=====> Epoch 10, Average Loss: 106.240\n",
            "=====> Average Test Loss: 105.588\n"
          ]
        }
      ],
      "source": [
        "# Main function\n",
        "for epoch in range(1, epochs + 1):\n",
        "    \"\"\"\n",
        "    训练和测试VAE模型，并在每个训练轮次结束后生成样本图像。\n",
        "    \"\"\"\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():# 去掉编码器，从高斯分布中采样z，并将其输入解码器生成样本\n",
        "        # Get rid of the encoder and sample z from the gaussian ditribution and feed it to the decoder to generate samples\n",
        "        sample = torch.randn(64,20).to(device)\n",
        "        generated = model.decode(sample).cpu()\n",
        "        save_image(generated.view(64,1,28,28), 'results/sample_' + str(epoch) + '.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 代码逐行解释\n",
        "\n",
        "```python\n",
        "# 主函数\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    with torch.no_grad():\n",
        "        # 去掉编码器，从高斯分布中采样z，并将其输入解码器生成样本\n",
        "        sample = torch.randn(64, 20).to(device)\n",
        "        generated = model.decode(sample).cpu()\n",
        "        save_image(generated.view(64, 1, 28, 28), 'results/sample_' + str(epoch) + '.png')\n",
        "```\n",
        "这段代码定义了训练和测试VAE模型的主循环，并在每个训练轮次结束后生成样本图像：\n",
        "- `for epoch in range(1, epochs + 1)`：遍历每个训练轮次。\n",
        "  - `train(epoch)`：调用训练函数进行训练。\n",
        "  - `test(epoch)`：调用测试函数进行测试。\n",
        "  - `with torch.no_grad()`：在不计算梯度的上下文中生成样本。\n",
        "    - `sample = torch.randn(64, 20).to(device)`：从标准正态分布中采样64个潜在变量，每个变量的维度为20，并将其移动到指定设备（如GPU）。\n",
        "    - `generated = model.decode(sample).cpu()`：将采样的潜在变量输入解码器生成样本，并将生成的样本移动到CPU。\n",
        "    - `save_image(generated.view(64, 1, 28, 28), 'results/sample_' + str(epoch) + '.png')`：将生成的样本保存为图像文件。\n",
        "\n",
        "### 参数详细解释\n",
        "\n",
        "#### `torch.randn(size)`\n",
        "- `size`：生成张量的形状，数据类型为元组。例如，`(64, 20)`表示生成64个20维的标准正态分布样本。\n",
        "\n",
        "#### `to(device)`\n",
        "- `device`：指定设备，数据类型为字符串或`torch.device`对象。例如，`'cuda'`表示使用GPU。\n",
        "\n",
        "#### `cpu()`\n",
        "- 将张量从GPU移动到CPU。\n",
        "\n",
        "#### `view(*shape)`\n",
        "- `shape`：新的形状，数据类型为整数。例如，`(64, 1, 28, 28)`表示将张量重新形状为64个1x28x28的图像。\n",
        "\n",
        "#### `save_image(tensor, filename, nrow)`\n",
        "- `tensor`：要保存的图像张量，数据类型为`torch.Tensor`。\n",
        "- `filename`：保存的文件名，数据类型为字符串。\n",
        "- `nrow`：每行显示的图像数量，数据类型为整数。\n",
        "\n",
        "### 函数选择分析\n",
        "\n",
        "#### `torch.randn`\n",
        "- 选择原因：生成标准正态分布样本，用于从潜在空间中采样潜在变量。\n",
        "- 替代方案：可以使用`numpy.random.randn`生成样本，但需要转换为`torch.Tensor`。\n",
        "\n",
        "#### `to`\n",
        "- 选择原因：将张量移动到指定设备（如GPU），以加速计算。\n",
        "- 替代方案：无直接替代方案。\n",
        "\n",
        "#### `cpu`\n",
        "- 选择原因：将张量从GPU移动到CPU，以便后续处理和保存。\n",
        "- 替代方案：无直接替代方案。\n",
        "\n",
        "#### `view`\n",
        "- 选择原因：重新形状张量，以便保存为图像。\n",
        "- 替代方案：可以使用`reshape`，但`view`更高效。\n",
        "\n",
        "#### `save_image`\n",
        "- 选择原因：保存图像，用于可视化生成样本。\n",
        "- 替代方案：可以使用`matplotlib`等库进行图像保存，但`save_image`更简洁。\n",
        "\n",
        "### 专门分析领域\n",
        "\n",
        "#### 生成样本\n",
        "- 从标准正态分布中采样潜在变量，并通过解码器生成样本图像。\n",
        "- 生成的样本图像可以用于评估模型的生成能力和潜在空间的质量。\n",
        "\n",
        "#### 数据处理函数\n",
        "- `randn`：生成标准正态分布样本，用于从潜在空间中采样潜在变量。\n",
        "- `to`：将张量移动到指定设备（如GPU），以加速计算。\n",
        "- `cpu`：将张量从GPU移动到CPU，以便后续处理和保存。\n",
        "- `view`：重新形状张量，以便保存为图像。\n",
        "- `save_image`：保存图像，用于可视化生成样本。\n",
        "\n",
        "### 参数特定指导\n",
        "\n",
        "#### 常见配置错误\n",
        "- `size`：确保生成的张量形状正确，避免维度错误。\n",
        "- `device`：确保指定的设备可用，避免设备错误。\n",
        "- `view`：确保重新形状后的张量形状正确，避免维度错误。\n",
        "\n",
        "#### 参数调优策略\n",
        "- 根据数据集和任务需求调整生成样本的数量和维度。\n",
        "- 选择合适的设备（如GPU）以加速计算。\n",
        "\n",
        "#### 输入验证建议\n",
        "- 确保输入数据的形状和类型正确，避免维度错误。\n",
        "- 在训练前对输入数据进行归一化或标准化处理，提高模型性能。\n",
        "\n",
        "### 建设性技术反馈\n",
        "\n",
        "1. **添加文档字符串**：\n",
        "   ```python\n",
        "   for epoch in range(1, epochs + 1):\n",
        "       \"\"\"\n",
        "       训练和测试VAE模型，并在每个训练轮次结束后生成样本图像。\n",
        "       \"\"\"\n",
        "       train(epoch)\n",
        "       test(epoch)\n",
        "       with torch.no_grad():\n",
        "           # 去掉编码器，从高斯分布中采样z，并将其输入解码器生成样本\n",
        "           sample = torch.randn(64, 20).to(device)\n",
        "           generated = model.decode(sample).cpu()\n",
        "           save_image(generated.view(64, 1, 28, 28), 'results/sample_' + str(epoch) + '.png')\n",
        "   ```\n",
        "\n",
        "2. **优化生成样本的代码**：\n",
        "   ```python\n",
        "   with torch.no_grad():\n",
        "       sample = torch.randn(64, latent_dim).to(device)\n",
        "       generated = model.decode(sample).cpu()\n",
        "       save_image(generated.view(64, 1, 28, 28), 'results/sample_' + str(epoch) + '.png')\n",
        "   ```\n",
        "\n",
        "### 总结\n",
        "\n",
        "总体而言，代码结构清晰，逻辑正确，符合编码标准。通过添加文档字符串和优化部分计算，可以进一步提高代码的可读性和性能。"
      ],
      "metadata": {
        "id": "v3PAFWVaogQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YvLn7BdBZhEL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}