{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install scipy"
      ],
      "metadata": {
        "id": "qLwhVQtbizum"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MwTZoGcjdwA8"
      },
      "outputs": [],
      "source": [
        "# 导入必要的深度学习库，用于神经网络操作\n",
        "# torch 提供张量计算和自动微分功能\n",
        "import torch\n",
        "\n",
        "# 导入 torch.nn 模块，用于构建神经网络\n",
        "import torch.nn as nn\n",
        "\n",
        "# 导入 torchvision.transforms 模块，用于图像预处理\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 导入 torch.nn.functional 模块，提供常用的神经网络功能\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 从 scipy.misc 导入 imread 和 imresize 函数，用于读取和调整图像大小\n",
        "# from scipy.misc import imread, imresize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hypothesis\n",
        "The error message ImportError: cannot import name 'imread' from 'scipy.misc' indicates that the functions imread and imresize are no longer available in the scipy.misc module. These functions were deprecated in SciPy 1.0.0 and removed in SciPy 1.3.0.\n",
        "\n",
        "#### Suggested Changes\n",
        "Instead of using imread and imresize from scipy.misc, you should use imageio.imread and PIL.Image.resize for reading and resizing images. Here's the modified code:\n",
        "\n",
        "```python\n",
        "!pip install imageio pillow\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from PIL import Image\n",
        "\n",
        "def process_image(image):\n",
        "    # Use imageio.imread to read the image\n",
        "    img = imageio.imread(image)  \n",
        "    \n",
        "    # Use PIL.Image.resize to resize the image\n",
        "    img = Image.fromarray(img).resize((256, 256))  \n",
        "    img = np.array(img)  # Convert back to numpy array\n",
        "    \n",
        "    img = img.transpose(2, 0, 1)\n",
        "    img = img / 255.\n",
        "    img = torch.FloatTensor(img).cuda()\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    transform = transforms.Compose([normalize])\n",
        "    img = transform(img)\n",
        "    return img\n",
        "```\n",
        "#### Explanation of Changes:\n",
        "\n",
        "1. Install necessary packages: We install imageio and pillow using !pip install imageio pillow.\n",
        "2. Import necessary modules: We import imageio and Image from PIL.\n",
        "3. Replace imread: We use imageio.imread(image) to read the image.\n",
        "4. Replace imresize: We use Image.fromarray(img).resize((256, 256)) to resize the image, converting it back to a NumPy array using np.array(img) afterwards.\n",
        "\n",
        "##### way2\n",
        "Okay, if you prefer to solely utilize SciPy for this task, you can leverage the scipy.ndimage.zoom function for resizing images. However, please note that while scipy.ndimage.zoom offers resizing capabilities, it is generally recommended to use dedicated image processing libraries like Pillow or OpenCV for more robust and efficient image resizing operations.\n",
        "\n",
        "Here's the modified code using scipy.ndimage.zoom:\n",
        "```python\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from scipy import ndimage\n",
        "import scipy\n",
        "\n",
        "def process_image(image):\n",
        "    # Use scipy.ndimage.imread to read the image\n",
        "    img = scipy.ndimage.imread(image)\n",
        "    \n",
        "    # Use scipy.ndimage.zoom to resize the image\n",
        "    img = scipy.ndimage.zoom(img, (256 / img.shape[0], 256 / img.shape[1], 1))\n",
        "    \n",
        "    img = img.transpose(2, 0, 1)\n",
        "    img = img / 255.\n",
        "    img = torch.FloatTensor(img).cuda()\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    transform = transforms.Compose([normalize])\n",
        "    img = transform(img)\n",
        "    return img\n",
        "```\n",
        "\n",
        "##### Explanation of Changes:\n",
        "\n",
        "1. Import scipy.ndimage: We import ndimage from scipy.\n",
        "2. Replace imread: We use scipy.ndimage.imread(image) to read the image. Since you want to only use SciPy, we will use the imread function from scipy.ndimage for consistency, although it's also deprecated.\n",
        "3. Replace imresize: We use scipy.ndimage.zoom to resize the image.\n",
        "   - We calculate the zoom factors by dividing the target size (256) by the original image dimensions.\n",
        "   - We set the zoom factor for the third dimension (color channels) to 1 to avoid resizing the color channels.\n",
        "\n",
        "##### Important Considerations:\n",
        "\n",
        "- Deprecated imread: Please note that scipy.ndimage.imread is also deprecated. While this solution addresses your preference for using SciPy only, it's worth considering migrating to other image processing libraries for future compatibility.\n",
        "- Interpolation: The scipy.ndimage.zoom function uses spline interpolation by default. If you require a specific interpolation method, you can adjust the order parameter. Please refer to the SciPy documentation for more details.\n",
        "\n",
        "By using scipy.ndimage.zoom, you can resize images within your code while solely relying on SciPy. However, remember the considerations mentioned above and explore alternative libraries for more robust and efficient image processing tasks in the long run."
      ],
      "metadata": {
        "id": "7N_H3hqUjE10"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQzHy6NvdwA_"
      },
      "source": [
        "### Saving the model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WeM7bryndwBB"
      },
      "outputs": [],
      "source": [
        "# # 定义图像处理函数\n",
        "# def process_image(image):\n",
        "#     # 读取图像文件\n",
        "#     img = imread(image)\n",
        "\n",
        "#     # 调整图像大小为 256x256\n",
        "#     img = imresize(img, (256, 256))   # 256x256x3\n",
        "\n",
        "#     # 转换图像通道顺序为 channels first 格式\n",
        "#     img = img.transpose(2, 0, 1)   # channels first\n",
        "\n",
        "#     # 将图像像素值归一化到 [0, 1] 范围\n",
        "#     img = img / 255.\n",
        "\n",
        "#     # 将图像转换为 PyTorch 张量并移动到 GPU\n",
        "#     img = torch.FloatTensor(img).cuda()\n",
        "\n",
        "#     # 定义图像归一化操作，使用 ImageNet 数据集的均值和标准差\n",
        "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "#     # 将归一化操作组合成一个变换\n",
        "#     transform = transforms.Compose([normalize])\n",
        "\n",
        "#     # 对图像应用归一化变换\n",
        "#     img = transform(img)  # (3, 256, 256)\n",
        "\n",
        "#     # 返回处理后的图像张量\n",
        "#     return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def process_image(image):# 定义图像处理函数\n",
        "    # Use imageio.imread to read the image\n",
        "    img = imageio.imread(image)\n",
        "\n",
        "    # Use PIL.Image.resize to resize the image\n",
        "    img = Image.fromarray(img).resize((256, 256))\n",
        "    img = np.array(img)  # Convert back to numpy array\n",
        "\n",
        "    img = img.transpose(2, 0, 1)   # 转换图像通道顺序为 channels first 格式\n",
        "    img = img / 255.\n",
        "    img = torch.FloatTensor(img).cuda()  # 将图像转换为 PyTorch 张量并移动到 GPU\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 定义图像归一化操作，使用 ImageNet 数据集的均值和标准差\n",
        "    transform = transforms.Compose([normalize])\n",
        "    img = transform(img)\n",
        "    return img"
      ],
      "metadata": {
        "id": "knc5To6xjsMx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "这段视频的目的其实就是对模型进行保存和加载。所以我们不会真正关注建立一个非常好的卷积网络，这只是一个非常基础的例子，向你展示概念保存该模型然后重新加载它。"
      ],
      "metadata": {
        "id": "07aXhi__hruq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hUWVYZJgdwBC"
      },
      "outputs": [],
      "source": [
        "# 定义卷积神经网络模型\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        # 调用父类构造函数，初始化神经网络模块\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # 定义第一个卷积层，输入通道数为 3，输出通道数为 6，卷积核大小为 5x5，无填充，步幅为 1\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "\n",
        "        # 定义最大池化层，池化窗口大小为 2x2，步幅为 2\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # 定义第二个卷积层，输入通道数为 6，输出通道数为 12，卷积核大小为 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "\n",
        "        # 定义第一个全连接层，输入特征数为 12 * 61 * 61，输出特征数为 120\n",
        "        self.fc1 = nn.Linear(12 * 61 * 61, 120)\n",
        "\n",
        "        # 定义第二个全连接层，输入特征数为 120，输出特征数为 10\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 对输入图像应用第一个卷积层和 ReLU 激活函数\n",
        "        x = F.relu(self.conv1(x))  # 输出大小 = [ (256 - 5 + 2(0) ) / 1 ] + 1 --> 252x252\n",
        "\n",
        "        # 对卷积层输出应用最大池化层\n",
        "        x = self.pool(x)  # 输出大小 = 252 / 2 --> 126x126\n",
        "\n",
        "        # 对池化层输出应用第二个卷积层和 ReLU 激活函数\n",
        "        x = F.relu(self.conv2(x))  # 输出大小 = [ (126 - 5 + 2(0) ) / 1 ] + 1 --> 122x122\n",
        "\n",
        "        # 对卷积层输出应用最大池化层\n",
        "        x = self.pool(x)  # 输出大小 = 122 / 2 --> 61x61\n",
        "\n",
        "        # 将卷积层输出展平为一维张量\n",
        "        x = x.view(-1, 12 * 61 * 61)  # (1, 44652)\n",
        "\n",
        "        # 对展平后的张量应用第一个全连接层和 ReLU 激活函数\n",
        "        x = F.relu(self.fc1(x))  # (1, 120)\n",
        "\n",
        "        # 对全连接层输出应用第二个全连接层\n",
        "        x = self.fc2(x)  # (1, 10)\n",
        "\n",
        "        # 返回模型输出\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qLAcFrGCdwBD"
      },
      "outputs": [],
      "source": [
        "# Initialize model # 初始化卷积神经网络模型\n",
        "model = CNN()\n",
        "model = model.cuda() # 将模型移动到 GPU\n",
        "# Initialize optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # 初始化优化器，使用随机梯度下降法，学习率为 0.001，动量为 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Cn7Ipno7dwBE",
        "outputId": "9abca2c6-70b8-4f9a-b919-bd3a12abfcea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-cd8cfb0f77c0>:11: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  img = imageio.imread(image)\n"
          ]
        }
      ],
      "source": [
        "image = process_image('test.jpg')\n",
        "image = image.unsqueeze(0)      #batch dimension # 为图像增加一个批次维度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hum2NMKXdwBE",
        "outputId": "1e38c919-506e-4181-e2a5-9048aac20615",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "output = model(image) # 将图像输入模型，获取输出\n",
        "print(output.shape) # 打印模型输出的形状"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "a6w7BjwFdwBF",
        "outputId": "8ad7041e-392d-4c98-978e-dee61287ac8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
            "conv1.bias \t torch.Size([6])\n",
            "conv2.weight \t torch.Size([12, 6, 5, 5])\n",
            "conv2.bias \t torch.Size([12])\n",
            "fc1.weight \t torch.Size([120, 44652])\n",
            "fc1.bias \t torch.Size([120])\n",
            "fc2.weight \t torch.Size([10, 120])\n",
            "fc2.bias \t torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# Print model's state_dict # 打印模型的状态字典\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wye3KK0ndwBF"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model.pth.tar') # 保存模型的状态字典到文件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "is_H3te1dwBG",
        "outputId": "1e41c244-1bf3-465d-d522-ddfbd7bc77af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-0899fa2f1ca9>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model.pth.tar')) # 加载模型的状态字典\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=44652, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#model = CNN()\n",
        "model.load_state_dict(torch.load('model.pth.tar')) # 加载模型的状态字典\n",
        "model.eval()     #set dropout and batch normalization layers to evaluation mode before inference (testing) # 设置模型为评估模式，关闭 dropout 和 batch normalization 层"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "你提供的输出是一个卷积神经网络（CNN）的结构信息。让我们逐步解析这个网络的各个部分：\n",
        "\n",
        "1. **`conv1`:** 这是第一个卷积层。\n",
        "   - 输入通道数：3（通常表示RGB图像的三个颜色通道）\n",
        "   - 输出通道数：6（卷积层的输出通道数）\n",
        "   - 卷积核大小：5x5\n",
        "   - 步幅（stride）：1x1\n",
        "\n",
        "2. **`pool`:** 这是一个最大池化层（Max Pooling Layer）。\n",
        "   - 池化窗口大小：2x2\n",
        "   - 步幅：2x2\n",
        "   - 填充（padding）：0\n",
        "   - 膨胀（dilation）：1\n",
        "   - ceil_mode：False（表示是否使用天花板模式）\n",
        "\n",
        "3. **`conv2`:** 这是第二个卷积层。\n",
        "   - 输入通道数：6（来自第一个卷积层的输出）\n",
        "   - 输出通道数：12\n",
        "   - 卷积核大小：5x5\n",
        "   - 步幅：1x1\n",
        "\n",
        "4. **`fc1`:** 这是第一个全连接层（Fully Connected Layer）。\n",
        "   - 输入特征数：44652（这是卷积层和池化层输出的展平后的特征数）\n",
        "   - 输出特征数：120\n",
        "\n",
        "5. **`fc2`:** 这是第二个全连接层。\n",
        "   - 输入特征数：120（来自第一个全连接层的输出）\n",
        "   - 输出特征数：10（通常表示分类任务中的类别数）\n",
        "\n",
        "总结来说，这个网络首先通过两个卷积层和一个池化层提取图像的特征，然后通过两个全连接层进行分类。`model.eval()` 表示将模型设置为评估模式，这在进行推理时是必要的，因为某些层（如Dropout和BatchNorm）在训练和评估时的行为不同。\n",
        "\n",
        "这个网络结构通常用于图像分类任务，其中输入是RGB图像，输出是10个类别中的一个。"
      ],
      "metadata": {
        "id": "imdJNvhsB1qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 代码优化建议\n",
        "1. **图像处理优化**：\n",
        "   - 使用 `PIL` 库替代 `scipy.misc` 进行图像读取和调整大小操作，因为 `scipy.misc` 已被弃用。\n",
        "   - 使用 `torchvision.transforms` 提供的变换函数进行图像预处理。\n",
        "\n",
        "2. **模型定义优化**：\n",
        "   - 在模型定义中添加批量归一化层（Batch Normalization）以加速训练和提高模型性能。\n",
        "   - 使用更深层次的卷积神经网络结构，如 ResNet 或 VGG，以提高模型的表达能力。\n",
        "\n",
        "3. **优化器选择**：\n",
        "   - 考虑使用 Adam 优化器，它通常比 SGD 收敛更快，且对学习率不太敏感。\n",
        "\n",
        "4. **代码结构优化**：\n",
        "   - 将图像处理和模型定义分离到不同的模块中，以提高代码的可读性和可维护性。\n",
        "\n",
        "### 优化后的代码示例\n",
        "```python\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def process_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    img = transform(img)\n",
        "    return img.cuda()\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 12, 5)\n",
        "        self.fc1 = nn.Linear(12 * 61 * 61, 120)\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 12 * 61 * 61)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "image = process_image('test.jpg')\n",
        "image = image.unsqueeze(0)\n",
        "output = model(image)\n",
        "print(output.shape)\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pth.tar')\n",
        "model.load_state_dict(torch.load('model.pth.tar'))\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "通过这些优化，代码的可读性、可维护性和性能都得到了提升。"
      ],
      "metadata": {
        "id": "gCjmuHk0radu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrjPcKjJdwBG"
      },
      "source": [
        "### Saving & Loading a General Checkpoint for Inference and/or Resuming Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AtCll5T0dwBH"
      },
      "outputs": [],
      "source": [
        "model = CNN().cuda() # 初始化卷积神经网络模型并移动到 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KB6S4EsJdwBH"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # 初始化优化器，使用随机梯度下降法，学习率为 0.001，动量为 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_4yBwG8ydwBH"
      },
      "outputs": [],
      "source": [
        "# 创建一个字典来保存训练检查点，包括当前的 epoch、模型状态字典、优化器状态字典和损失值\n",
        "checkpoint = {'epoch': 1, # 当前训练的 epoch 数\n",
        "            'model_state_dict': model.state_dict(),# 模型的状态字典\n",
        "            'optimizer_state_dict': optimizer.state_dict(),# 优化器的状态字典\n",
        "            'loss': 0.2}  # 当前的损失值\n",
        "torch.save(checkpoint, 'model.pth.tar')# 将检查点保存到文件 'model.pth.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gzLTjp73dwBH",
        "outputId": "16fb6b5b-bf77-45c4-ce55-cb6c302c1a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-3d69c587b9be>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('model.pth.tar')\n"
          ]
        }
      ],
      "source": [
        "checkpoint = torch.load('model.pth.tar')# 从文件 'model.pth.tar' 加载检查点"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IMQX3qlCdwBI"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(checkpoint['model_state_dict']) # 加载模型的状态字典\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])# 加载优化器的状态字典\n",
        "epoch = checkpoint['epoch']# 恢复训练的 epoch 数\n",
        "loss = checkpoint['loss']# 恢复训练的损失值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CDMOOUEJdwBI",
        "outputId": "08abaaf7-b722-419f-94f5-4c26f0b441a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=44652, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# If testing\n",
        "model.eval() # 如果进行测试，设置模型为评估模式，关闭 dropout 和 batch normalization 层\n",
        "# If resume training\n",
        "model.train() # 如果继续训练，设置模型为训练模式，启用 dropout 和 batch normalization 层"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "优化后的代码示例"
      ],
      "metadata": {
        "id": "NpyHwe1aBham"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 初始化卷积神经网络模型并移动到 GPU\n",
        "model = CNN().cuda()\n",
        "\n",
        "# 初始化优化器，使用随机梯度下降法，学习率为 0.001，动量为 0.9\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 创建一个字典来保存训练检查点，包括当前的 epoch、模型状态字典、优化器状态字典和损失值\n",
        "checkpoint = {\n",
        "    'epoch': 1,  # 当前训练的 epoch 数\n",
        "    'model_state_dict': model.state_dict(),  # 模型的状态字典\n",
        "    'optimizer_state_dict': optimizer.state_dict(),  # 优化器的状态字典\n",
        "    'loss': 0.2  # 当前的损失值\n",
        "}\n",
        "\n",
        "# 将检查点保存到文件 'model.pth.tar'\n",
        "torch.save(checkpoint, 'model.pth.tar')\n",
        "\n",
        "# 从文件 'model.pth.tar' 加载检查点\n",
        "if os.path.isfile('model.pth.tar'):\n",
        "    checkpoint = torch.load('model.pth.tar')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"Checkpoint loaded: epoch {epoch}, loss {loss}\")\n",
        "else:\n",
        "    print(\"No checkpoint found, starting from scratch\")\n",
        "\n",
        "# 如果进行测试，设置模型为评估模式，关闭 dropout 和 batch normalization 层\n",
        "if testing:\n",
        "    model.eval()\n",
        "else:\n",
        "    # 如果继续训练，设置模型为训练模式，启用 dropout 和 batch normalization 层\n",
        "    model.train()\n"
      ],
      "metadata": {
        "id": "-MA_JJgsBgQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}