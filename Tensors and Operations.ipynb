{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTZ6GJ6rPY9n"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELgOY9g1PY9o"
      },
      "source": [
        "# Torch Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IqwZpVjPY9p",
        "outputId": "7a1707e3-7420-4f07-96de-d27a0a34098b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "#This is a 1-D Tensor\n",
        "a = torch.tensor([2,2,1])\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlAG8thzPY9p",
        "outputId": "3f5bf2f6-5efb-4e0d-d236-e361c30d2005",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 1, 4],\n",
            "        [3, 5, 4],\n",
            "        [1, 2, 0],\n",
            "        [4, 3, 2]])\n"
          ]
        }
      ],
      "source": [
        "#This is a 2-D Tensor\n",
        "b = torch.tensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_x2ImT3PY9p",
        "outputId": "19fab10a-476a-4ba3-b829-80b19c359944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3])\n",
            "torch.Size([4, 3])\n",
            "torch.Size([3])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "#The size of the tensors\n",
        "print(a.shape) # attribute\n",
        "print(b.shape)\n",
        "print(a.size()) # method\n",
        "print(b.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNh70WCTPY9q",
        "outputId": "0eed2094-dcb8-4ba9-b796-0c2ed7724a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ],
      "source": [
        "#Get the height/number of rows of b\n",
        "print(b.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM48cWZRPY9q"
      },
      "outputs": [],
      "source": [
        "c = torch.FloatTensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
        "#or we can do\n",
        "# c = torch.tensor([2,2,1], dtype = torch.float)\n",
        "# c = torch.tensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]], dtype = torch.float)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdaH5-6HPY9q"
      },
      "outputs": [],
      "source": [
        "d = torch.DoubleTensor([[2,1,4],[3,5,4],[1,2,0],[4,3,2]])\n",
        "#or we can do\n",
        "#d = torch.tensor([2,2,1], dtype = torch.double)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTK00iQKPY9q",
        "outputId": "f9235c80-25f9-4b4e-c87b-ff791146cfb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 1., 4.],\n",
            "        [3., 5., 4.],\n",
            "        [1., 2., 0.],\n",
            "        [4., 3., 2.]])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(c)\n",
        "print(c.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD9aj2DOPY9r",
        "outputId": "45cfd013-3db0-4308-f6f7-147d1e706aa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 1., 4.],\n",
            "        [3., 5., 4.],\n",
            "        [1., 2., 0.],\n",
            "        [4., 3., 2.]], dtype=torch.float64)\n",
            "torch.float64\n"
          ]
        }
      ],
      "source": [
        "print(d)\n",
        "print(d.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMiU4ISzPY9r",
        "outputId": "725db7ca-a56f-49cd-a5da-d2d56935ddca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.5833)\n"
          ]
        }
      ],
      "source": [
        "print(c.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyCgJLVrPY9r",
        "outputId": "059611db-076c-46c6-bef2-f1038974e8ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.5833, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(d.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_opJ2JjPY9s",
        "outputId": "4ba8ba35-e182-4ba8-950b-505eed3c72d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5050)\n"
          ]
        }
      ],
      "source": [
        "print(c.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7LOHqL8PY9s",
        "outputId": "29e68b79-b292-4992-f45a-cf3de16209ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.5050, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "print(d.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk8-tDoUPY9s",
        "outputId": "bc76edd7-1d60-473c-8892-21a8d0dae7c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2],\n",
            "        [1],\n",
            "        [4],\n",
            "        [3],\n",
            "        [5],\n",
            "        [4],\n",
            "        [1],\n",
            "        [2],\n",
            "        [0],\n",
            "        [4],\n",
            "        [3],\n",
            "        [2]])\n",
            "tensor([2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2])\n",
            "tensor([[2, 1, 4, 3],\n",
            "        [5, 4, 1, 2],\n",
            "        [0, 4, 3, 2]])\n",
            "tensor([[2, 1, 4, 3],\n",
            "        [5, 4, 1, 2],\n",
            "        [0, 4, 3, 2]])\n",
            "tensor([[2, 1, 4, 3, 5, 4, 1, 2, 0, 4, 3, 2]])\n",
            "torch.Size([1, 12])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tensor([[[ 0.5572, -0.0966, -0.8857, -0.0790],\n",
            "         [-1.0658, -1.3216,  1.6341, -0.6019],\n",
            "         [ 0.4852,  0.1547, -0.5259,  0.0062]],\n",
            "\n",
            "        [[ 1.2748,  0.8993,  1.4589, -0.0152],\n",
            "         [ 0.1439,  1.5730, -0.2731,  1.1150],\n",
            "         [ 0.0346,  0.3214,  0.2166, -1.2798]]])\n",
            "tensor([[ 0.5572, -0.0966, -0.8857, -0.0790, -1.0658, -1.3216,  1.6341, -0.6019,\n",
            "          0.4852,  0.1547, -0.5259,  0.0062],\n",
            "        [ 1.2748,  0.8993,  1.4589, -0.0152,  0.1439,  1.5730, -0.2731,  1.1150,\n",
            "          0.0346,  0.3214,  0.2166, -1.2798]])\n",
            "tensor([[ 0.5572, -0.0966, -0.8857, -0.0790, -1.0658, -1.3216,  1.6341, -0.6019,\n",
            "          0.4852,  0.1547, -0.5259,  0.0062],\n",
            "        [ 1.2748,  0.8993,  1.4589, -0.0152,  0.1439,  1.5730, -0.2731,  1.1150,\n",
            "          0.0346,  0.3214,  0.2166, -1.2798]])\n"
          ]
        }
      ],
      "source": [
        "#Reshape b\n",
        "#Note: If one of the dimensions is -1, its size can be inferred\n",
        "print(b.view(-1,1)) # the method to reshapre a tensor is called view\n",
        "print(b.view(12))\n",
        "print(b.view(-1,4)) # row, column\n",
        "print(b.view(3,4))\n",
        "#Assign b a new shape\n",
        "b = b.view(1,-1)\n",
        "print(b)\n",
        "print(b.shape)\n",
        "#We can even reshape 3D tensors\n",
        "print('\\n')\n",
        "#Create a 3D Tensor with 2 channels, 3 rows and 4 columns (channles,rows,columns)\n",
        "three_dim = torch.randn(2, 3, 4)\n",
        "print('\\n')\n",
        "print(three_dim)\n",
        "print(three_dim.view(2, 12))  # Reshape to 2 rows, 12 columns\n",
        "print(three_dim.view(2, -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZQC5TXHPY9s",
        "outputId": "5b6bc952-aa22-4649-8fd2-588dcfe35423",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1655, 0.5509, 0.7215, 0.4266],\n",
            "        [0.5039, 0.6241, 0.6375, 0.0086],\n",
            "        [0.8058, 0.3813, 0.5304, 0.6250],\n",
            "        [0.7783, 0.9672, 0.5758, 0.9691]])\n"
          ]
        }
      ],
      "source": [
        "#Create a matrix with random numbers between 0 and 1\n",
        "r = torch.rand(4,4)\n",
        "print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIDjemK3PY9t",
        "outputId": "9e1ebb1e-b78a-4760-e099-4ee88f600710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.2221,  0.5479, -0.1081,  2.5792],\n",
            "        [-0.1063,  0.1902,  0.4066, -0.7872],\n",
            "        [-0.4863, -0.5022, -0.0705,  0.5866],\n",
            "        [ 0.7790, -0.4010, -1.4613,  1.7189]])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "#Create a matrix with random numbers taken from a normal distribution with mean 0 and variance 1\n",
        "r2 = torch.randn(4,4)\n",
        "print(r2)\n",
        "print(r2.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swws_P3SPY9t",
        "outputId": "510f4177-c5f3-48c7-e674-d90342df522a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8, 9, 9, 6, 7])\n",
            "torch.int64\n"
          ]
        }
      ],
      "source": [
        "#Create an array of 5 random integers from values between 6 and 9 (exlusive of 10)\n",
        "in_array = torch.randint(6,10, (5,))\n",
        "print(in_array)\n",
        "print(in_array.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ug-4TlH2PY9t",
        "outputId": "1003f98a-136d-4de2-890e-8f329e26b5d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9, 7, 7],\n",
            "        [9, 7, 6],\n",
            "        [7, 7, 8]])\n"
          ]
        }
      ],
      "source": [
        "#Create a 2-D array (or matrix) of size 3x3 filled with random integers from values between 6 and 9 (exlusive of 10)\n",
        "in_array2 = torch.randint(6,10, (3,3))\n",
        "print(in_array2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTZbA1FnPY9t",
        "outputId": "3ee2e907-14da-4549-dcbd-d8b127c167f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "#Get the number of elemetns in in_array\n",
        "print(torch.numel(in_array))\n",
        "#Get the number of elemetns in in_array\n",
        "print(torch.numel(in_array2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPCvjd1YPY9u",
        "outputId": "e28d0c19-d5a4-4bea-91f7-bb84ff0b0ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "#Construct a 3x3 matrix of zeros and of dtype long:\n",
        "z = torch.zeros(3, 3, dtype=torch.long)\n",
        "print(z)\n",
        "#Construct a 3x3 matrix of ones\n",
        "o = torch.ones(3,3) # if you don't give dtype, it will use default one - float\n",
        "print(o)\n",
        "print(o.dtype)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ndQ7rkvPY9u",
        "outputId": "6c03bb74-c468-465d-979f-ea402571674f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.6390,  0.1016,  0.3886,  1.7789],\n",
            "        [ 0.5381,  0.7601, -0.6157,  1.8600],\n",
            "        [ 1.5001,  0.7930,  0.2296,  0.3817],\n",
            "        [-1.1445,  0.2986,  0.5821, -0.8531]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "r2_like = torch.randn_like(r2, dtype=torch.double)    # Convert the data type of the tensor\n",
        "print(r2_like) # randn_like - Randn_like，所以这基本上意味着与我们之前学习过的 .Randn 函数相同。然而，当我们放入 _like 时，它​​就占据了 R2 的大小。你正在生成随机整数大小与R2相同，类型为torch.double。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3I57H8IPY9u",
        "outputId": "0e645462-a769-4c77-e8fd-bb9a551d4b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3876,  1.0988,  0.6134,  3.0058],\n",
            "        [ 0.3976,  0.8143,  1.0441, -0.7786],\n",
            "        [ 0.3195, -0.1209,  0.4599,  1.2116],\n",
            "        [ 1.5573,  0.5661, -0.8855,  2.6880]])\n"
          ]
        }
      ],
      "source": [
        "#Add two tensors, make sure they are the same size and data type\n",
        "add_result = torch.add(r,r2)\n",
        "print(add_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AuYM8ggEPY9u",
        "outputId": "74373f4f-3447-46a4-81d0-0410f59224ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3876,  1.0988,  0.6134,  3.0058],\n",
            "        [ 0.3976,  0.8143,  1.0441, -0.7786],\n",
            "        [ 0.3195, -0.1209,  0.4599,  1.2116],\n",
            "        [ 1.5573,  0.5661, -0.8855,  2.6880]])\n"
          ]
        }
      ],
      "source": [
        "#In-place addition (change the value of r2)\n",
        "r2.add_(r)    # if you don't want to reassign a new variables, you can directly use like this\n",
        "print(r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HtSOQIzPY9u",
        "outputId": "a3d0f36a-187b-41d5-f40b-c7ee6d9e53b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0988,  0.8143, -0.1209,  0.5661])\n",
            "tensor([[ 1.3876,  1.0988],\n",
            "        [ 0.3976,  0.8143],\n",
            "        [ 0.3195, -0.1209],\n",
            "        [ 1.5573,  0.5661]])\n",
            "tensor([[ 1.3876,  1.0988,  0.6134,  3.0058],\n",
            "        [ 0.3976,  0.8143,  1.0441, -0.7786],\n",
            "        [ 0.3195, -0.1209,  0.4599,  1.2116]])\n",
            "tensor(1.2116)\n",
            "1.2115864753723145\n",
            "tensor([ 0.3195, -0.1209,  0.4599,  1.2116])\n"
          ]
        }
      ],
      "source": [
        "print(r2[:,1]) #all rows, column 1 (start from 0 )\n",
        "print(r2[:,:2]) # all rows, first two column\n",
        "print(r2[:3,:])# first three rows, all column\n",
        "num_ten = r2[2,3]  #这只是一个具有一个数字的张量。\n",
        "print(num_ten)\n",
        "print(num_ten.item()) # 只需访问张量内部的这个数字\n",
        "print(r2[2,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j9mjeyePY9u"
      },
      "source": [
        "## Numpy Bridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9_TZQSoPY9u"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMpIhVcjPY9v",
        "outputId": "290ef31b-6e0d-4a97-fac2-333b3f6c3fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "#Converting a Torch Tensor to a NumPy Array\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "#See how the numpy array changed their value.\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b) # 因此 NumPy 数组实际上受到 Torch 张量的影响，这被称为 NumPy Bridge，这就是如何将 Torch Tensor 转换为对 NumPy 数组也影响 NumPy 数组，所以无论 Torch 张量发生什么,在 NumPy 数组上也会发生这种情况。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FEhTDZzPY9v",
        "outputId": "d0700686-b9d9-4426-8ae9-3ff214235e44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "#Converting NumPy Array to Torch Tensor\n",
        "#See how changing the np array changed the Torch Tensor automatically\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b) # 反过来也一样, 互相影响"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMWxMEd8PY9v",
        "outputId": "21e9ed53-5dea-4e8b-af12-b56e47f22980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3876,  1.0988,  0.6134,  3.0058],\n",
            "        [ 0.3976,  0.8143,  1.0441, -0.7786],\n",
            "        [ 0.3195, -0.1209,  0.4599,  1.2116],\n",
            "        [ 1.5573,  0.5661, -0.8855,  2.6880]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#Move the tensor to the GPU\n",
        "r2 = r2.cuda() #将张量移动到 GPU 的方式\n",
        "print(r2)\n",
        "# 当你想做一些 GPU 计算时加快计算速度,它只是为了加速你的神经网络，那么你当然需要使用你的 GPU,这就是将张量移动到 GPU 的方法"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaib5gcFPY9v",
        "outputId": "47400fc5-7abe-4fda-c976-4593c6736b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "tensor([[ 1.3876,  1.0988,  0.6134,  3.0058],\n",
            "        [ 0.3976,  0.8143,  1.0441, -0.7786],\n",
            "        [ 0.3195, -0.1209,  0.4599,  1.2116],\n",
            "        [ 1.5573,  0.5661, -0.8855,  2.6880]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "#Provide Easy switching between CPU and GPU\n",
        "CUDA = torch.cuda.is_available()\n",
        "print(CUDA)\n",
        "if CUDA:\n",
        "    add_result = add_result.cuda()\n",
        "    print(add_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht65Di62PY9v",
        "outputId": "347f6f06-aacb-4baf-f1b2-6f9f752b2fb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 4, 1]\n",
            "tensor([2, 3, 4, 1]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "#You can also convert a list to a tensor\n",
        "a = [2,3,4,1]\n",
        "print(a)\n",
        "to_list = torch.tensor(a)\n",
        "print(to_list, to_list.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R_QV0hyPY9w",
        "outputId": "f92a05db-c455-471d-814f-a04bf723f985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.],\n",
            "        [7., 8.]]) torch.float32\n"
          ]
        }
      ],
      "source": [
        "data =  [[1., 2.], [3., 4.],\n",
        "         [5., 6.], [7., 8.]]\n",
        "T = torch.tensor(data)\n",
        "print(T, T.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXmZvtm_PY9w"
      },
      "source": [
        "## Tensor Concatenation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhcHlW5PPY9w",
        "outputId": "6f032a3c-460b-4ec3-f186-86d54344df63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3764, -0.8490,  0.2908,  0.7473, -1.0248],\n",
            "        [ 0.9702, -0.0897, -1.7068, -0.0574, -0.4710]])\n",
            "tensor([[-0.8916,  1.1353, -0.0939,  0.5517,  1.9676],\n",
            "        [ 2.3614, -0.4936, -1.3871, -1.6027,  0.7342],\n",
            "        [-1.5270, -0.1521,  1.3709,  0.8060, -0.1269]])\n",
            "\n",
            "\n",
            "tensor([[ 1.3764, -0.8490,  0.2908,  0.7473, -1.0248],\n",
            "        [ 0.9702, -0.0897, -1.7068, -0.0574, -0.4710],\n",
            "        [-0.8916,  1.1353, -0.0939,  0.5517,  1.9676],\n",
            "        [ 2.3614, -0.4936, -1.3871, -1.6027,  0.7342],\n",
            "        [-1.5270, -0.1521,  1.3709,  0.8060, -0.1269]])\n",
            "\n",
            "\n",
            "tensor([[ 0.0645, -0.7634,  0.7345],\n",
            "        [-0.7834, -0.4485,  0.1668]])\n",
            "tensor([[ 1.9943,  0.9285, -0.0825,  0.0257, -0.8608],\n",
            "        [-0.4569, -0.5723, -0.2055, -0.5542, -1.4182]])\n",
            "\n",
            "\n",
            "tensor([[ 0.0645, -0.7634,  0.7345,  1.9943,  0.9285, -0.0825,  0.0257, -0.8608],\n",
            "        [-0.7834, -0.4485,  0.1668, -0.4569, -0.5723, -0.2055, -0.5542, -1.4182]])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Tensor Concatenation 张量连接\n",
        "first_1 = torch.randn(2, 5)\n",
        "print(first_1)\n",
        "second_1 = torch.randn(3, 5)\n",
        "print(second_1)\n",
        "#Concatenate along the 0 dimension (concatenate rows)\n",
        "con_1 = torch.cat([first_1, second_1])  # 按列连接 上下\n",
        "print('\\n')\n",
        "print(con_1)\n",
        "print('\\n')\n",
        "first_2 = torch.randn(2, 3)\n",
        "print(first_2)\n",
        "second_2 = torch.randn(2, 5)\n",
        "print(second_2)\n",
        "# Concatenate along the 1 dimension (concatenate columns)\n",
        "con_2 = torch.cat([first_2, second_2], 1) # 按行连接 左右\n",
        "print('\\n')\n",
        "print(con_2)\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt1-YfegPY9w"
      },
      "source": [
        "## Adding Dimensions to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-VtTSRwPY9w",
        "outputId": "0a5f19c5-6c97-4132-eea0-d926357341be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4])\n",
            "tensor([[1, 2, 3, 4]])\n",
            "torch.Size([1, 4])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]])\n",
            "torch.Size([4, 1])\n",
            "\n",
            "\n",
            "tensor([[[0.6682, 0.8206, 0.5863, 0.5804],\n",
            "         [0.3732, 0.7078, 0.2448, 0.7527],\n",
            "         [0.4562, 0.4420, 0.0282, 0.6540]],\n",
            "\n",
            "        [[0.9072, 0.2776, 0.5350, 0.9259],\n",
            "         [0.7868, 0.0957, 0.2005, 0.3234],\n",
            "         [0.9085, 0.7758, 0.9320, 0.5884]]])\n",
            "\n",
            "\n",
            "tensor([[0.5863, 0.2448, 0.0282],\n",
            "        [0.5350, 0.2005, 0.9320]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "\n",
            "tensor([[[0.5863],\n",
            "         [0.2448],\n",
            "         [0.0282]],\n",
            "\n",
            "        [[0.5350],\n",
            "         [0.2005],\n",
            "         [0.9320]]])\n",
            "torch.Size([2, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "#Adds a dimension of 1 along a specified index\n",
        "tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "print(tensor_1.shape)\n",
        "tensor_a = torch.unsqueeze(tensor_1, 0)  #这行代码在 tensor_1 的第0维（即最外层）增加一个维度。结果是一个二维张量 tensor_a，其形状为 [1, 4]\n",
        "print(tensor_a)\n",
        "print(tensor_a.shape)\n",
        "tensor_b = torch.unsqueeze(tensor_1,1) #这行代码在 tensor_1 的第1维（即第二个维度）增加一个维度。结果是一个二维张量 tensor_b，其形状为 [4, 1]\n",
        "print(tensor_b)\n",
        "print(tensor_b.shape)\n",
        "print('\\n')\n",
        "tensor_2 = torch.rand(2,3,4)\n",
        "print(tensor_2)\n",
        "print('\\n')\n",
        "tensor_c = tensor_2[:,:,2] #这行代码从 tensor_2 中提取出第三个维度（索引为2）的所有元素，结果是一个形状为 [2, 3] 的二维张量 tensor_c\n",
        "print(tensor_c)\n",
        "print(tensor_c.shape) #torch.Size([2, 3])\n",
        "print('\\n')\n",
        "tensor_d = torch.unsqueeze(tensor_c,2) #这行代码在 tensor_c 的第2维（即第三个维度）增加一个维度。结果是一个形状为 [2, 3, 1] 的三维张量 tensor_d\n",
        "print(tensor_d)\n",
        "print(tensor_d.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kcxcqOMPY9w"
      },
      "source": [
        "## AutoGrad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC7T95DGPY9x",
        "outputId": "c35228f0-eff9-413b-893d-cdb13ac2b5f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7c3295d89000>\n",
            "tensor(21., grad_fn=<SumBackward0>)\n",
            "<SumBackward0 object at 0x7c3295d8ae90>\n"
          ]
        }
      ],
      "source": [
        "#Remember, If requires_grad=True, the Tensor object keeps track of how it was created.\n",
        "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
        "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
        "#Notice that both x and y have their required_grad set to true, therefore we an compute gradients with respect to them\n",
        "z = x + y\n",
        "print(z)\n",
        "# z knows that is was created as a result of addition of x and y. It knows that it wasn't read in from a file\n",
        "print(z.grad_fn) #现在 Z 知道它是被创造出来的, Z 知道这是 X 和 Y 相加的结果,这就是 grad 函数。\n",
        "#And if we go further on this\n",
        "s = z.sum()\n",
        "print(s)\n",
        "print(s.grad_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy8SOf2wPY91",
        "outputId": "89f0554c-a1da-4375-fe02-8e4072f94a2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "#Now if we backpropagate on s, we can find the gradients of s with respect to x\n",
        "s.backward()\n",
        "print(x.grad)\n",
        "#当我们调用 s.backward 时，然后计算所有的梯度。关于变量的所有梯度,这里的 require_grad 等于 True。所以它只会计算图表中同时显示所有梯度,\n",
        "#正如我们在理论部分看到的那样。如果我们想访问这里的任何变量，如果我们想得到 S 相对于 X 的梯度，那么这就是我们所做的x.grad。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyGzegqVPY91",
        "outputId": "e2a5e6e4-e2d2-413f-da9f-ce97f3a13f14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False False\n",
            "None\n",
            "<AddBackward0 object at 0x7c3295ddf430>\n",
            "True\n",
            "None\n",
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "# By default, Tensors have `requires_grad=False`\n",
        "x = torch.randn(2, 2)\n",
        "y = torch.randn(2, 2)\n",
        "print(x.requires_grad, y.requires_grad)\n",
        "z = x + y\n",
        "# So you can't backprop through z\n",
        "# 因为默认情况下，X 和 Y 的 require_grad 等于 false。现在如果我们选择 Z，好吧，如果我们将 X 和 Y 相加并将结果存储在 Z 中\n",
        "# 然后我们打印 grad 函数，那么你将得到 None,因为没有跟踪计算,因此，Z 不知道是谁创造了它，因为 X 和 Y 没有require_grad 标志等于 True。\n",
        "# 所以这意味着你不能通过 Z 进行反向传播。\n",
        "print(z.grad_fn)\n",
        "#Another way to set the requires_grad = True is\n",
        "x.requires_grad_()\n",
        "y.requires_grad_()\n",
        "# z contains enough information to compute gradients, as we saw above\n",
        "z = x + y\n",
        "print(z.grad_fn)\n",
        "# If any input to an operation has ``requires_grad=True``, so will the output\n",
        "print(z.requires_grad)\n",
        "# Now z has the computation history that relates itself to x and y\n",
        "\n",
        "new_z = z.detach()\n",
        "print(new_z.grad_fn)\n",
        "# z.detach() returns a tensor that shares the same storage as ``z``, but with the computation history forgotten.\n",
        "#It doesn't know anything about how it was computed.In other words, we have broken the Tensor away from its past history\n",
        "\n",
        "#You can also stop autograd from tracking history on Tensors. This concept is useful when applying Transfer Learning\n",
        "#detach 的一个功能,可以停止 AutoGrad通过跟踪张量的历史。这个概念在应用迁移学习时很有用。\n",
        "print(x.requires_grad)\n",
        "print((x+10).requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    print((x+10).requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOpjlM3MPY91",
        "outputId": "4f6d0657-b265-4bef-e285-2c4eb24f993d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n",
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7c3295dddae0>\n",
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ]
        }
      ],
      "source": [
        "#Let's walk in through one last example\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "print(z, out)\n",
        "out.backward() #out.backward() 计算 out 相对于 x 的梯度，并将结果存储在 x.grad 中\n",
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mgDN5nLPY91",
        "outputId": "f7c4cf78-8534-4191-e0ef-eee80d7a1c24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "m1 = torch.ones(5,5)\n",
        "m2 = torch.zeros(5,5)\n",
        "#Perform element-wise multiplaction\n",
        "mul = torch.mul(m1,m2)\n",
        "#Another way to perform element-wise multiplaction\n",
        "mul_another = m1*m2\n",
        "print(mul)\n",
        "print(mul_another)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6kQkpLkPY91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}