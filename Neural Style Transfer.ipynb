{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAU6XImbomWz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8oSTAjOomW0"
      },
      "outputs": [],
      "source": [
        "def get_image(path, img_transform, size = (300,300)):\n",
        "    image = Image.open(path)\n",
        "    image = image.resize(size, Image.LANCZOS)\n",
        "    image = img_transform(image).unsqueeze(0)\n",
        "    return image.to(device)\n",
        "\n",
        "def get_gram(m):\n",
        "    '''\n",
        "    m is of shape(1,C,H,W)\n",
        "    '''\n",
        "    _, c, h, w = m.size()\n",
        "    m = m.view(c, h * w)\n",
        "    m = torch.mm(m, m.t())\n",
        "    return m\n",
        "\n",
        "def denormalize_img(inp):\n",
        "    inp = inp.numpy().transpose((1, 2, 0)) # C,H,W --> (H,W,C)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comprehensive Code Explanation\n",
        "\n",
        "#### Function: `get_image`\n",
        "\n",
        "```python\n",
        "def get_image(path, img_transform, size=(300, 300)):\n",
        "    image = Image.open(path)\n",
        "    image = image.resize(size, Image.LANCZOS)\n",
        "    image = img_transform(image).unsqueeze(0)\n",
        "    return image.to(device)\n",
        "```\n",
        "\n",
        "1. **Line-by-line Breakdown:**\n",
        "   - `def get_image(path, img_transform, size=(300, 300)):`: 定义一个名为 `get_image` 的函数，接受三个参数：`path`（图像路径），`img_transform`（图像变换函数），`size`（图像调整大小，默认为300x300）。\n",
        "   - `image = Image.open(path)`: 使用PIL库打开指定路径的图像文件。\n",
        "   - `image = image.resize(size, Image.LANCZOS)`: 将图像调整为指定大小，使用LANCZOS滤波器进行高质量的缩放。\n",
        "   - `image = img_transform(image).unsqueeze(0)`: 对图像应用变换函数，并增加一个维度（通常用于批处理）。\n",
        "   - `return image.to(device)`: 将图像移动到指定设备（如GPU）并返回。\n",
        "\n",
        "2. **Purpose and Functionality:**\n",
        "   - 该函数用于加载、调整大小并转换图像，以便在深度学习模型中使用。\n",
        "\n",
        "3. **Technical Reasoning:**\n",
        "   - 使用LANCZOS滤波器进行高质量缩放。\n",
        "   - 增加维度以适应批处理需求。\n",
        "   - 将图像移动到指定设备以加速计算。\n",
        "\n",
        "#### Function: `get_gram`\n",
        "\n",
        "```python\n",
        "def get_gram(m):\n",
        "    _, c, h, w = m.size()\n",
        "    m = m.view(c, h * w)\n",
        "    m = torch.mm(m, m.t())\n",
        "    return m\n",
        "```\n",
        "\n",
        "1. **Line-by-line Breakdown:**\n",
        "   - `def get_gram(m):`: 定义一个名为 `get_gram` 的函数，接受一个参数 `m`（特征图）。\n",
        "   - `_, c, h, w = m.size()`: 获取特征图的尺寸（批次大小、通道数、高度、宽度）。\n",
        "   - `m = m.view(c, h * w)`: 将特征图重塑为二维张量，形状为（通道数，高度*宽度）。\n",
        "   - `m = torch.mm(m, m.t())`: 计算特征图的Gram矩阵。\n",
        "   - `return m`: 返回Gram矩阵。\n",
        "\n",
        "2. **Purpose and Functionality:**\n",
        "   - 该函数用于计算特征图的Gram矩阵，常用于风格迁移任务中。\n",
        "\n",
        "3. **Technical Reasoning:**\n",
        "   - Gram矩阵用于捕捉特征图中的风格信息。\n",
        "\n",
        "#### Function: `denormalize_img`\n",
        "\n",
        "```python\n",
        "def denormalize_img(inp):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp\n",
        "```\n",
        "\n",
        "1. **Line-by-line Breakdown:**\n",
        "   - `def denormalize_img(inp):`: 定义一个名为 `denormalize_img` 的函数，接受一个参数 `inp`（归一化图像）。\n",
        "   - `inp = inp.numpy().transpose((1, 2, 0))`: 将张量转换为NumPy数组并调整维度顺序。\n",
        "   - `mean = np.array([0.485, 0.456, 0.406])`: 定义均值数组。\n",
        "   - `std = np.array([0.229, 0.224, 0.225])`: 定义标准差数组。\n",
        "   - `inp = std * inp + mean`: 反归一化图像。\n",
        "   - `inp = np.clip(inp, 0, 1)`: 将图像像素值限制在0到1之间。\n",
        "   - `return inp`: 返回反归一化后的图像。\n",
        "\n",
        "2. **Purpose and Functionality:**\n",
        "   - 该函数用于将归一化图像转换回原始图像，以便进行可视化。\n",
        "\n",
        "3. **Technical Reasoning:**\n",
        "   - 反归一化步骤使得图像可以在标准显示设备上正确显示。\n",
        "\n",
        "### Multilevel Function and Parameter Analysis\n",
        "\n",
        "#### Function: `get_image`\n",
        "\n",
        "**A. Detailed Parameter Explanation:**\n",
        "- `path`: 图像文件路径，字符串类型，必须是有效的文件路径。\n",
        "- `img_transform`: 图像变换函数，通常是由`torchvision.transforms`定义的变换序列。\n",
        "- `size`: 图像调整大小，元组类型，包含两个整数，表示宽度和高度。\n",
        "\n",
        "**B. Function Context Analysis:**\n",
        "- 选择该函数是为了简化图像预处理步骤。\n",
        "- 可替代实现：直接在数据加载器中进行图像变换。\n",
        "- 性能和设计考虑：使用LANCZOS滤波器进行高质量缩放。\n",
        "\n",
        "#### Function: `get_gram`\n",
        "\n",
        "**A. Detailed Parameter Explanation:**\n",
        "- `m`: 特征图，PyTorch张量，形状为（批次大小，通道数，高度，宽度）。\n",
        "\n",
        "**B. Function Context Analysis:**\n",
        "- 选择该函数是为了计算特征图的Gram矩阵，用于风格迁移。\n",
        "- 可替代实现：使用其他矩阵操作库。\n",
        "- 性能和设计考虑：使用矩阵乘法计算Gram矩阵。\n",
        "\n",
        "#### Function: `denormalize_img`\n",
        "\n",
        "**A. Detailed Parameter Explanation:**\n",
        "- `inp`: 归一化图像，PyTorch张量，形状为（通道数，高度，宽度）。\n",
        "\n",
        "**B. Function Context Analysis:**\n",
        "- 选择该函数是为了将归一化图像转换回原始图像。\n",
        "- 可替代实现：在图像显示时进行反归一化。\n",
        "- 性能和设计考虑：使用NumPy进行高效数组操作。\n",
        "\n",
        "### Specialized Analysis Areas\n",
        "\n",
        "#### Function Choice Insights\n",
        "\n",
        "- `get_image`函数选择了LANCZOS滤波器进行高质量缩放，这是为了在图像预处理中保持图像质量。\n",
        "- `get_gram`函数使用矩阵乘法计算Gram矩阵，这是为了高效捕捉特征图中的风格信息。\n",
        "- `denormalize_img`函数使用NumPy进行反归一化，这是为了高效处理数组操作。\n",
        "\n",
        "#### Activation Functions\n",
        "\n",
        "- 本代码未涉及激活函数，但在深度学习模型中，激活函数的选择对模型性能有重要影响。\n",
        "\n",
        "#### Data Processing Functions\n",
        "\n",
        "- `get_image`和`denormalize_img`函数涉及图像处理，前者用于预处理，后者用于反归一化。\n",
        "\n",
        "### Code Review Dimensions\n",
        "\n",
        "- **Syntax Correctness:** 代码语法正确，无明显错误。\n",
        "- **Performance Optimization Opportunities:** 可以考虑在数据加载器中进行图像变换以提高效率。\n",
        "- **Coding Best Practices Adherence:** 代码结构清晰，函数命名合理。\n",
        "- **Algorithmic Improvement Potential:** 可以进一步优化图像处理步骤以提高性能。\n",
        "\n",
        "### Parameter-Specific Guidance\n",
        "\n",
        "- **Common Configuration Mistakes:** 确保图像路径有效，变换函数正确定义。\n",
        "- **Parameter Tuning Strategies:** 根据具体任务调整图像大小和变换函数。\n",
        "- **Input Validation Recommendations:** 添加输入验证以确保图像路径和变换函数有效。\n",
        "\n",
        "### Constructive Technical Feedback\n",
        "\n",
        "- **Improvement Suggestions:**\n",
        "  - 在`get_image`函数中添加输入验证。\n",
        "  - 在`denormalize_img`函数中添加对输入类型的检查。\n",
        "  \n",
        "- **Rationale for Recommended Modifications:**\n",
        "  - 输入验证可以提高代码的鲁棒性，防止无效输入导致错误。\n",
        "  \n",
        "- **Concrete Implementation Examples:**\n",
        "\n",
        "```python\n",
        "def get_image(path, img_transform, size=(300, 300)):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Image path {path} does not exist.\")\n",
        "    image = Image.open(path)\n",
        "    image = image.resize(size, Image.LANCZOS)\n",
        "    image = img_transform(image).unsqueeze(0)\n",
        "    return image.to(device)\n",
        "\n",
        "def denormalize_img(inp):\n",
        "    if not isinstance(inp, torch.Tensor):\n",
        "        raise TypeError(\"Input must be a PyTorch tensor.\")\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp\n",
        "```\n",
        "\n",
        "通过这些改进，可以提高代码的鲁棒性和可维护性。"
      ],
      "metadata": {
        "id": "ZkhbAS8-0vV_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg9GX_s5omW0"
      },
      "source": [
        "![figure](https://user-images.githubusercontent.com/30661597/107026142-96fa0100-67aa-11eb-9f71-4adce01dd362.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyhee2LeomW1"
      },
      "outputs": [],
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.selected_layers = [3, 8, 15, 22]\n",
        "        self.vgg = models.vgg16(pretrained=True).features\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer_features = []\n",
        "        for layer_number, layer in self.vgg._modules.items():\n",
        "            x = layer(x)\n",
        "            if int(layer_number) in self.selected_layers:\n",
        "                layer_features.append(x)\n",
        "        return layer_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56mFbHm2omW1"
      },
      "outputs": [],
      "source": [
        "img_transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))])\n",
        "\n",
        "content_img = get_image('content.jpg', img_transform)\n",
        "style_img = get_image('style.jpg', img_transform)\n",
        "generated_img = content_img.clone()    # or nn.Parameter(torch.FloatTensor(content_img.size()))\n",
        "generated_img.requires_grad = True\n",
        "\n",
        "optimizer = torch.optim.Adam([generated_img], lr=0.003, betas=[0.5, 0.999])\n",
        "encoder = FeatureExtractor().to(device)\n",
        "\n",
        "for p in encoder.parameters():\n",
        "    p.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxfNLD1womW1"
      },
      "outputs": [],
      "source": [
        "content_weight = 1\n",
        "style_weight = 100\n",
        "\n",
        "for epoch in range(500):\n",
        "\n",
        "    content_features = encoder(content_img)\n",
        "    style_features = encoder(style_img)\n",
        "    generated_features = encoder(generated_img)\n",
        "\n",
        "    content_loss = torch.mean((content_features[-1] - generated_features[-1])**2)\n",
        "\n",
        "    style_loss = 0\n",
        "    for gf, sf in zip(generated_features, style_features):\n",
        "        _, c, h, w = gf.size()\n",
        "        gram_gf = get_gram(gf)\n",
        "        gram_sf = get_gram(sf)\n",
        "        style_loss += torch.mean((gram_gf - gram_sf)**2)  / (c * h * w)\n",
        "\n",
        "    loss = content_weight * content_loss + style_weight * style_loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print ('Epoch [{}]\\tContent Loss: {:.4f}\\tStyle Loss: {:.4f}'.format(epoch, content_loss.item(), style_loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8d8RilsomW1"
      },
      "outputs": [],
      "source": [
        "inp = generated_img.detach().cpu().squeeze()\n",
        "inp = denormalize_img(inp)\n",
        "plt.imshow(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Rx6dPsomW2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}