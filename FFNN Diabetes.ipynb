{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### data preprocessing\n",
        "\n"
      ],
      "metadata": {
        "id": "QGK35AjeFDnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q5JcvFjqgPAx"
      },
      "outputs": [],
      "source": [
        "import numpy as np #可以用它来构建矩阵。Python 列表非常慢，所以当你想做一些矩阵乘法时或者一些矩阵运算，那么对列表的操作就会非常慢。因此当你使用 NumPy 时并创建 NumPy 数组或 NumPy 矩阵，那么你的矩阵运算当然会快得多。\n",
        "import torch\n",
        "import torch.nn as nn #负责所有神经网络类别和功能\n",
        "import pandas as pd #帮助我们预处理数据集\n",
        "from sklearn.preprocessing import StandardScaler #帮助我们预处理数据集\n",
        "from torch.utils.data import Dataset #将要使用的另一个类构建我们的 PyTorch 数据集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ylAumLCvgPAz"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using Pandas\n",
        "data = pd.read_csv('diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "4u4n34X1CfgM",
        "outputId": "8dffbb40-af34-4e62-83b2-da10c47ad866",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Number of times pregnant  Plasma glucose concentration  \\\n",
              "0                         6                           148   \n",
              "1                         1                            85   \n",
              "2                         8                           183   \n",
              "3                         1                            89   \n",
              "4                         0                           137   \n",
              "\n",
              "   Diastolic blood pressure  Triceps skin fold thickness  \\\n",
              "0                        72                           35   \n",
              "1                        66                           29   \n",
              "2                        64                            0   \n",
              "3                        66                           23   \n",
              "4                        40                           35   \n",
              "\n",
              "   2-Hour serum insulin  Body mass index  Age     Class  \n",
              "0                     0             33.6   50  positive  \n",
              "1                     0             26.6   31  negative  \n",
              "2                     0             23.3   32  positive  \n",
              "3                    94             28.1   21  negative  \n",
              "4                   168             43.1   33  positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edbd1185-80f1-44a2-b032-1355a24b0ca1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Number of times pregnant</th>\n",
              "      <th>Plasma glucose concentration</th>\n",
              "      <th>Diastolic blood pressure</th>\n",
              "      <th>Triceps skin fold thickness</th>\n",
              "      <th>2-Hour serum insulin</th>\n",
              "      <th>Body mass index</th>\n",
              "      <th>Age</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>50</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>31</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>32</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>21</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>33</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edbd1185-80f1-44a2-b032-1355a24b0ca1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edbd1185-80f1-44a2-b032-1355a24b0ca1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edbd1185-80f1-44a2-b032-1355a24b0ca1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dc076f5e-1f59-4c82-8030-59e87d163998\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc076f5e-1f59-4c82-8030-59e87d163998')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dc076f5e-1f59-4c82-8030-59e87d163998 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Number of times pregnant\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Plasma glucose concentration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Diastolic blood pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Triceps skin fold thickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"2-Hour serum insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Body mass index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"negative\",\n          \"positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "SwygIs0oCl9O",
        "outputId": "7033bdd4-50ad-436e-fcce-6089c1c0e70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 768 entries, 0 to 767\n",
            "Data columns (total 8 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   Number of times pregnant      768 non-null    int64  \n",
            " 1   Plasma glucose concentration  768 non-null    int64  \n",
            " 2   Diastolic blood pressure      768 non-null    int64  \n",
            " 3   Triceps skin fold thickness   768 non-null    int64  \n",
            " 4   2-Hour serum insulin          768 non-null    int64  \n",
            " 5   Body mass index               768 non-null    float64\n",
            " 6   Age                           768 non-null    int64  \n",
            " 7   Class                         768 non-null    object \n",
            "dtypes: float64(1), int64(6), object(1)\n",
            "memory usage: 48.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ssDfW68WgPA0"
      },
      "outputs": [],
      "source": [
        "# For x: Extract out the dataset from all the rows (all samples) and all columns except last column (all features).\n",
        "# For y: Extract out the last column (which is the label)\n",
        "# Convert both to numpy array using the .values method\n",
        "x = data.iloc[:,0:-1].values # change the result to array\n",
        "y_string= list(data.iloc[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gb9-Oz3hgPA0",
        "outputId": "e8502838-692e-4743-e238-09abc7a9ef52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.  148.   72.   35.    0.   33.6  50. ]\n",
            " [  1.   85.   66.   29.    0.   26.6  31. ]\n",
            " [  8.  183.   64.    0.    0.   23.3  32. ]]\n",
            "['positive', 'negative', 'positive']\n"
          ]
        }
      ],
      "source": [
        "# Lets have a look some samples from our data\n",
        "print(x[:3])\n",
        "print(y_string[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RvGjsFZCgPA0"
      },
      "outputs": [],
      "source": [
        "# Our neural network only understand numbers! So convert the string to labels\n",
        "y_int = []\n",
        "for string in y_string:\n",
        "    if string == 'positive':\n",
        "        y_int.append(1)\n",
        "    else:\n",
        "        y_int.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_int[:3])"
      ],
      "metadata": {
        "id": "UnFk8ks7EJok",
        "outputId": "083e3c36-d795-42d9-aa16-b2b732d1bba3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gFK_ACUZgPA1"
      },
      "outputs": [],
      "source": [
        "# Now convert y_int list to an array\n",
        "y = np.array(y_int, dtype = 'float64') #正在做一个神经网络,并且所有内容都必须采用数组或矩阵格式\n",
        "#在我们转换成 NumPy 之后，我们还需要将其转换为张量，即 PyTorch 张量"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:3])"
      ],
      "metadata": {
        "id": "DxxUQZ1KEjBW",
        "outputId": "faf3d263-692c-4c4e-80f5-15a2d8e1c36f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "CRaj69r9Em9o",
        "outputId": "da6ea369-09cc-45ef-ffb5-7ad7bd601770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
              "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPeiHo9DgPA1"
      },
      "source": [
        "### feature/data normalization\n",
        "### $x^{\\prime}=\\frac{x-\\mu}{\\sigma}$\n",
        "\n",
        "Why, How and When to Scale your Features:\n",
        "https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e\n",
        "这篇文章主要讨论了特征缩放（Feature Scaling）的重要性、方法以及何时应用这些方法。以下是文章的主要内容和关键知识点的解释：\n",
        "\n",
        "### 为什么需要特征缩放（Why Scaling）\n",
        "\n",
        "1. **数据特征差异**：在大多数情况下，数据集中的特征在大小、单位和范围上差异很大。由于大多数机器学习算法在计算中使用两点之间的欧几里得距离，这就成了一个问题。\n",
        "\n",
        "2. **特征影响**：如果不考虑特征的大小，算法在计算距离时只会考虑特征的大小而忽略单位，这会导致不同单位的特征在距离计算中的权重差异很大。\n",
        "\n",
        "### 如何缩放特征（How to Scale Features）\n",
        "\n",
        "文章介绍了四种常见的特征缩放方法：\n",
        "\n",
        "1. **标准化（Standardisation）**：\n",
        "   - 通过替换值为它们的Z分数来实现。\n",
        "   - 将特征重新分布，使其均值μ=0，标准差σ=1。\n",
        "   - `sklearn.preprocessing.scale` 可以帮助我们在Python中实现标准化。\n",
        "\n",
        "2. **均值归一化（Mean Normalisation）**：\n",
        "   - 这种分布的值将在-1和1之间，均值μ=0。\n",
        "   - 标准化和均值归一化可以用于假设零中心数据的算法，如主成分分析（PCA）。\n",
        "\n",
        "3. **最小-最大缩放（Min-Max Scaling）**：\n",
        "   - 这种缩放将值限制在0和1之间。\n",
        "\n",
        "4. **单位向量（Unit Vector）**：\n",
        "   - 缩放是考虑整个特征向量的长度为单位长度。\n",
        "   - 最小-最大缩放和单位向量技术产生的值范围是[0,1]。在处理具有硬边界的特征时非常有用，例如，处理图像数据时，颜色范围仅为0到255。\n",
        "\n",
        "### 何时缩放特征（When to Scale）\n",
        "\n",
        "1. **距离计算或假设正态性的算法**：任何计算距离或假设正态性的算法，都应该对特征进行缩放。\n",
        "\n",
        "2. **特定算法的例子**：\n",
        "   - **k-最近邻（k-nearest neighbors）**：使用欧几里得距离度量时，对特征的大小敏感，因此应该对所有特征进行缩放，以使它们平等地贡献。\n",
        "   - **主成分分析（PCA）**：PCA试图获得方差最大的特征，而方差对于高幅度特征更高。这会使PCA偏向高幅度特征。\n",
        "   - **梯度下降**：通过缩放可以加速梯度下降。这是因为θ在小范围内下降得快，在大范围内下降得慢，因此当变量非常不均匀时，会在最优解附近无效地振荡。\n",
        "   - **基于树的模型**：不是基于距离的模型，可以处理不同范围的特征。因此，在建模树时不需要缩放。\n",
        "   - **线性判别分析（LDA）和朴素贝叶斯（Naive Bayes）**：这些算法设计上能够处理这个问题，并相应地给特征分配权重。在这些算法中执行特征缩放可能没有太大效果。\n",
        "\n",
        "文章最后鼓励读者分享他们的最佳实践和经验法则，以供大家参考和学习。\n",
        "\n",
        "标准化（Standardisation）和均值归一化（Mean Normalisation）是两种不同的特征缩放技术，它们在处理数据时有着不同的方法和目的。以下是它们的主要区别：\n",
        "\n",
        "1. **标准化（Standardisation）**：\n",
        "   - **目的**：将特征的分布转换为均值（μ）为0，标准差（σ）为1的分布。这种转换有助于保持数据的原始分布形状和相对差异。\n",
        "   - **公式**：\\[ z = \\frac{x - \\mu}{\\sigma} \\]\n",
        "     其中 \\( x \\) 是原始数据点，\\( \\mu \\) 是样本均值，\\( \\sigma \\) 是样本标准差。\n",
        "   - **结果**：数据将被转换为标准正态分布，这意味着大多数数据（约68%）将位于-1和1之间，而不是-1和1之间。\n",
        "   - **适用情况**：适用于假设数据呈正态分布的算法，如线性回归、逻辑回归、神经网络等。也适用于需要保持数据分布特性的算法，如主成分分析（PCA）。\n",
        "\n",
        "2. **均值归一化（Mean Normalisation）**：\n",
        "   - **目的**：将特征缩放到一个固定的范围，通常是[-1, 1]。这种转换改变了数据的分布，使其适应特定的范围。\n",
        "   - **公式**：\\[ x' = \\frac{x - \\mu}{\\sigma} \\]\n",
        "     其中 \\( x \\) 是原始数据点，\\( \\mu \\) 是样本均值，\\( \\sigma \\) 是样本标准差。然后，将结果乘以2并减去1，以将数据缩放到[-1, 1]范围内。\n",
        "   - **结果**：数据将被缩放到[-1, 1]的范围内，这有助于某些算法更好地处理数据，特别是那些对数据范围敏感的算法。\n",
        "   - **适用情况**：适用于需要数据在特定范围内的算法，如支持向量机（SVM）和一些神经网络算法。也适用于数据预处理，以防止数值不稳定或溢出。\n",
        "\n",
        "总结来说，标准化保持了数据的原始分布特性，而均值归一化则将数据缩放到一个固定的范围。选择哪种方法取决于具体的算法需求和数据特性。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x #这些特征有不同的范围,我们需要对所有特征进行归一化,具有相同的范围。所以我们要做的是将每个特征标准化为一个范围介于-1和1之间。"
      ],
      "metadata": {
        "id": "t_YpMtR2FMxU",
        "outputId": "66db4811-f36e-4e74-e191-dbdcd026d125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6. , 148. ,  72. , ...,   0. ,  33.6,  50. ],\n",
              "       [  1. ,  85. ,  66. , ...,   0. ,  26.6,  31. ],\n",
              "       [  8. , 183. ,  64. , ...,   0. ,  23.3,  32. ],\n",
              "       ...,\n",
              "       [  5. , 121. ,  72. , ..., 112. ,  26.2,  30. ],\n",
              "       [  1. , 126. ,  60. , ...,   0. ,  30.1,  47. ],\n",
              "       [  1. ,  93. ,  70. , ...,   0. ,  30.4,  23. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NOtd9qzTgPA2"
      },
      "outputs": [],
      "source": [
        "# Feature Normalization. All features should have the same range of values (-1,1)\n",
        "sc = StandardScaler()\n",
        "x = sc.fit_transform(x) #首先，计算平均值以及数据集的标准差,并将此规则应用于您的数据集。因此拟合变换基本上就是计算值并将其应用到您的数据集。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "HLtD2WUSHFG-",
        "outputId": "2db9cd2e-75d5-44ed-e6b9-1d6cd361570c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.63994726,  0.84832379,  0.14964075, ..., -0.69289057,\n",
              "         0.20401277,  1.4259954 ],\n",
              "       [-0.84488505, -1.12339636, -0.16054575, ..., -0.69289057,\n",
              "        -0.68442195, -0.19067191],\n",
              "       [ 1.23388019,  1.94372388, -0.26394125, ..., -0.69289057,\n",
              "        -1.10325546, -0.10558415],\n",
              "       ...,\n",
              "       [ 0.3429808 ,  0.00330087,  0.14964075, ...,  0.27959377,\n",
              "        -0.73518964, -0.27575966],\n",
              "       [-0.84488505,  0.1597866 , -0.47073225, ..., -0.69289057,\n",
              "        -0.24020459,  1.17073215],\n",
              "       [-0.84488505, -0.8730192 ,  0.04624525, ..., -0.69289057,\n",
              "        -0.20212881, -0.87137393]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YRJG7KAPgPA2"
      },
      "outputs": [],
      "source": [
        "#我们已经完成了特征的标准化。现在我们需要做的是转换非 py 数组,由于我们正在使用 PyTorch，因此将其转换为 PyTorch 张量。我们将使用 PyTorch 构建我们的神经网络。然后我们需要将所有内容转换为 PyTorch 张量。\n",
        "# Now we convert the arrays to PyTorch tensors\n",
        "x = torch.tensor(x) #- x.shape is torch.Size([768,7])\n",
        "# We add an extra dimension to convert this array to 2D\n",
        "y = torch.tensor(y).unsqueeze(1)\n",
        "# y = torch.tensor(y)  - y.shape is torch.Size([768]) 现在意识到这只是一个维度。如果你这样做,稍后你将使用二元交叉熵,然后 PyTorch 会告诉你这需要是一个二维矩阵。所以这就是为什么我们需要在这里添加一个维度。我们需要将这个矩阵变成768乘以1。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `unsqueeze` 的作用\n",
        "\n",
        "在 PyTorch 中，`unsqueeze` 是一个用于在指定位置插入一个大小为1的新维度的操作。它的主要作用是改变张量的形状（shape），以便与其他张量进行操作时形状匹配。\n",
        "\n",
        "### 具体示例\n",
        "\n",
        "假设 `y` 是一个一维张量，其形状为 `[N]`，其中 `N` 是张量的长度。通过使用 `unsqueeze(1)`，我们在第1维（索引从0开始）插入一个新的维度，使其形状变为 `[N, 1]`。\n",
        "\n",
        "### 代码解释\n",
        "\n",
        "```python\n",
        "y = torch.tensor(y).unsqueeze(1)\n",
        "```\n",
        "\n",
        "1. `torch.tensor(y)`：将 `y` 转换为一个 PyTorch 张量。\n",
        "2. `.unsqueeze(1)`：在第1维插入一个新的维度，使张量的形状从 `[N]` 变为 `[N, 1]`。\n",
        "\n",
        "### 示例\n",
        "\n",
        "假设 `y` 是一个包含5个元素的一维张量：\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "y = [1, 2, 3, 4, 5]\n",
        "y_tensor = torch.tensor(y)\n",
        "print(y_tensor.shape)  # 输出: torch.Size([5])\n",
        "\n",
        "y_unsqueezed = y_tensor.unsqueeze(1)\n",
        "print(y_unsqueezed.shape)  # 输出: torch.Size([5, 1])\n",
        "print(y_unsqueezed)\n",
        "```\n",
        "\n",
        "输出结果：\n",
        "\n",
        "```\n",
        "torch.Size([5])\n",
        "torch.Size([5, 1])\n",
        "tensor([[1],\n",
        "        [2],\n",
        "        [3],\n",
        "        [4],\n",
        "        [5]])\n",
        "```\n",
        "\n",
        "可以看到，`unsqueeze(1)` 在第1维插入了一个新的维度，使得张量的形状从 `[5]` 变为 `[5, 1]`。\n",
        "\n",
        "### 代码优化建议\n",
        "\n",
        "如果你需要在多个地方使用 `unsqueeze` 操作，可以考虑将其封装成一个函数，以提高代码的可读性和复用性。\n",
        "\n",
        "```python\n",
        "import torch\n",
        "\n",
        "def to_column_vector(tensor):\n",
        "    \"\"\"\n",
        "    将一维张量转换为列向量。\n",
        "    \n",
        "    参数:\n",
        "    tensor (torch.Tensor): 输入的一维张量\n",
        "    \n",
        "    返回:\n",
        "    torch.Tensor: 转换后的列向量\n",
        "    \"\"\"\n",
        "    return tensor.unsqueeze(1)\n",
        "\n",
        "# 示例用法\n",
        "y = [1, 2, 3, 4, 5]\n",
        "y_tensor = torch.tensor(y)\n",
        "y_column_vector = to_column_vector(y_tensor)\n",
        "print(y_column_vector.shape)  # 输出: torch.Size([5, 1])\n",
        "print(y_column_vector)\n",
        "```\n",
        "\n",
        "这样可以使代码更加模块化和易读。"
      ],
      "metadata": {
        "id": "1iQHdD0OOB_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "SnbAP7uPLftT",
        "outputId": "09ed5235-2ef6-403c-b88d-2ce3c37fda06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6399,  0.8483,  0.1496,  ..., -0.6929,  0.2040,  1.4260],\n",
              "        [-0.8449, -1.1234, -0.1605,  ..., -0.6929, -0.6844, -0.1907],\n",
              "        [ 1.2339,  1.9437, -0.2639,  ..., -0.6929, -1.1033, -0.1056],\n",
              "        ...,\n",
              "        [ 0.3430,  0.0033,  0.1496,  ...,  0.2796, -0.7352, -0.2758],\n",
              "        [-0.8449,  0.1598, -0.4707,  ..., -0.6929, -0.2402,  1.1707],\n",
              "        [-0.8449, -0.8730,  0.0462,  ..., -0.6929, -0.2021, -0.8714]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:3])"
      ],
      "metadata": {
        "id": "fAe9HztBLheg",
        "outputId": "f55bf272-5c08-4c81-edf7-bcaece4b73d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.],\n",
            "        [0.],\n",
            "        [1.]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "v4XGoXBUgPA2",
        "outputId": "f0700179-7b42-4432-ddbf-ded784173c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([768, 7])\n",
            "torch.Size([768, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "y5hiVY3_gPA3"
      },
      "outputs": [],
      "source": [
        "class Dataset(Dataset): #这行代码定义了一个名为 Dataset 的类，并继承自 torch.utils.data.Dataset。注意，这里类名和导入的基类名相同，可能会引起混淆，建议使用不同的名称\n",
        "  #我们导入了数据集类(from torch.utils.data import Dataset).利用这些数据，所以我们要继承这个类并构建我们的自定义数据集。\n",
        "\n",
        "    def __init__(self,x,y): #这是类的构造函数 __init__，用于初始化数据集对象。它接受两个参数 x 和 y，并将它们存储为实例变量\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self,index): #这是 __getitem__ 方法，用于根据索引 index 获取数据集中的一个样本。它返回一个元组 (self.x[index], self.y[index])\n",
        "        # Get one item from the dataset\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self): #这是 __len__ 方法，用于返回数据集的大小，即数据集中样本的数量\n",
        "        return len(self.x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 代码解释\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset\n",
        "```\n",
        "这行代码从 `torch.utils.data` 模块导入 `Dataset` 类，这是 PyTorch 中用于创建自定义数据集的基类。\n",
        "\n",
        "```python\n",
        "class Dataset(Dataset):\n",
        "```\n",
        "这行代码定义了一个名为 `Dataset` 的类，并继承自 `torch.utils.data.Dataset`。注意，这里类名和导入的基类名相同，可能会引起混淆，建议使用不同的名称。\n",
        "\n",
        "```python\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "```\n",
        "这是类的构造函数 `__init__`，用于初始化数据集对象。它接受两个参数 `x` 和 `y`，并将它们存储为实例变量。\n",
        "\n",
        "```python\n",
        "    def __getitem__(self, index):\n",
        "        # Get one item from the dataset\n",
        "        return self.x[index], self.y[index]\n",
        "```\n",
        "这是 `__getitem__` 方法，用于根据索引 `index` 获取数据集中的一个样本。它返回一个元组 `(self.x[index], self.y[index])`。\n",
        "\n",
        "```python\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "```\n",
        "这是 `__len__` 方法，用于返回数据集的大小，即数据集中样本的数量。\n",
        "\n",
        "```python\n",
        "dataset = Dataset(x, y)\n",
        "```\n",
        "这行代码创建了一个 `Dataset` 类的实例 `dataset`，并传入数据 `x` 和 `y`。\n",
        "\n",
        "### 代码优化建议\n",
        "\n",
        "1. **类名**：为了避免与导入的基类名相同，建议使用不同的类名。\n",
        "2. **类型注解**：可以添加类型注解，以提高代码的可读性和可维护性。\n",
        "3. **文档字符串**：可以添加文档字符串，以便更好地描述类和方法的功能。\n",
        "\n",
        "优化后的代码如下：\n",
        "\n",
        "```python\n",
        "from torch.utils.data import Dataset as TorchDataset\n",
        "from typing import Any, Tuple\n",
        "\n",
        "class CustomDataset(TorchDataset):\n",
        "    \"\"\"\n",
        "    自定义数据集类，继承自 torch.utils.data.Dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x: Any, y: Any):\n",
        "        \"\"\"\n",
        "        初始化数据集对象。\n",
        "\n",
        "        参数:\n",
        "        x (Any): 输入数据\n",
        "        y (Any): 标签数据\n",
        "        \"\"\"\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
        "        \"\"\"\n",
        "        根据索引获取数据集中的一个样本。\n",
        "\n",
        "        参数:\n",
        "        index (int): 样本索引\n",
        "\n",
        "        返回:\n",
        "        Tuple[Any, Any]: 一个包含输入数据和标签的元组\n",
        "        \"\"\"\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        返回数据集的大小。\n",
        "\n",
        "        返回:\n",
        "        int: 数据集中样本的数量\n",
        "        \"\"\"\n",
        "        return len(self.x)\n",
        "\n",
        "# 示例用法\n",
        "# 假设 x 和 y 已经定义\n",
        "# x = ...\n",
        "# y = ...\n",
        "dataset = CustomDataset(x, y)\n",
        "```\n",
        "\n",
        "这样可以使代码更加清晰和易读，同时避免类名冲突。"
      ],
      "metadata": {
        "id": "JWXMwhQEP0Al"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fc7vhq92gPA3"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "LQfMRjrVP-G2",
        "outputId": "9463389e-ac29-46ca-ab4e-423b707acdce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Dataset at 0x7ef80ded83d0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1pzOtSfcgPA3",
        "outputId": "895cc242-3dce-4f50-fc08-e49acf5d7a3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M_L_9MyvgPA3"
      },
      "outputs": [],
      "source": [
        "# Load the data to your dataloader for batch processing and shuffling\n",
        "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                           batch_size=32,\n",
        "                                           shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "id": "JHBXVyJRQbWW",
        "outputId": "777c76f9-a8a3-4936-dd2a-4b482defc155",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7ef80ded9000>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "5ynWatLbgPA3",
        "outputId": "7968e9c8-a8a8-4001-eb1e-58a0c510127a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 24 batches in the dataset\n",
            "For one iteration (batch), there is:\n",
            "Data:    torch.Size([32, 7])\n",
            "Labels:  torch.Size([32, 1])\n"
          ]
        }
      ],
      "source": [
        "# Let's have a look at the data loader\n",
        "print(\"There is {} batches in the dataset\".format(len(train_loader)))\n",
        "for (x,y) in train_loader:\n",
        "    print(\"For one iteration (batch), there is:\")\n",
        "    print(\"Data:    {}\".format(x.shape))\n",
        "    print(\"Labels:  {}\".format(y.shape))\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6mDHWYRgPA3"
      },
      "source": [
        "![demo](https://user-images.githubusercontent.com/30661597/60379583-246e5e80-9a68-11e9-8b7f-a4294234c201.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "数据中有七个特征，我们有几个隐藏层，那么我们最终的输出层只有一个神经元。\n",
        "所以这个数字要么是0，要么是1，或者换句话说，是或否。\n",
        "所以我们要预测一个人是否患有糖尿病。"
      ],
      "metadata": {
        "id": "U2YhcwbCg4m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### building the network"
      ],
      "metadata": {
        "id": "iu3CpYyTQwG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2Xigo3cEScpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "从NN点模型类继承。那么让我们进入初始化函数。因此，再次定义 init，并且不要忘记 self。那么现在这个类的输入和参数是什么？\n",
        "当我们想要初始化这个类时，我们应该给出什么论据？因此我们需要给出输入的数量，功能，\n",
        "以及输出特征的数量。因此输出特征。现在隐藏功能的数量，我们只是要在内部进行设计。但你也可以隐藏第一层，然后隐藏第二层下划线。第三层也是如此。\n",
        "![image.png](data:image/png;base64,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)\n",
        "所以你可以这样做或者您可以直接在类内部对其进行硬编码。\n",
        "\n",
        "我们要做的就是直接传递类内隐藏神经元的数量。当我们初始化这个类时，我们只需要给出输入特征的数量以及输出特征的数量。\n",
        "\n",
        "那么我们的神经网络的属性是什么？基本上，他们是我们的层。它有哪些功能,我们的神经网络基本上是前向传播函数。"
      ],
      "metadata": {
        "id": "C6aXxzwzSnbc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "hvo-Jk0LgPA3"
      },
      "outputs": [],
      "source": [
        "# Now let's build the above network\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_features,output_features):\n",
        "        super(Model, self).__init__() #我们再次从这个父母那里继承了类，NN 点模型类。所以我们想利用所有的功能,此 NN 点模型类并将其传递给我们的模型类，我们正在创建的这个类。 所以使用super\n",
        "        self.fc1 = nn.Linear(input_features, 5) #每个类都需要有一些属性和一些功能。\n",
        "        self.fc2 = nn.Linear(5, 4)\n",
        "        self.fc3 = nn.Linear(4, 3)\n",
        "        self.fc4 = nn.Linear(3, output_features)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "现在，我们不需要建造或者编写我们的反向传播函数因为 PyTorch 会自动为我们完成这件事。我们要做的就是提供四个传播函数和 PyTorch，自动进行反向传播。因此它遵循这里的顺序。你放的，所以这里，这是我们放每一行的顺序。当反向传播发生时，它只是遵循相反的顺序前向传播函数。您可以定义自定义反向传播函数，但我们不会在这门课上这样做."
      ],
      "metadata": {
        "id": "QejC3Bp9V4UT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 代码解释\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "```\n",
        "这行代码导入了 `torch.nn` 模块，这是 PyTorch 中用于构建神经网络的模块。\n",
        "\n",
        "```python\n",
        "class Model(nn.Module):\n",
        "```\n",
        "这行代码定义了一个名为 `Model` 的类，并继承自 `torch.nn.Module`。这是创建自定义神经网络模型的标准做法。\n",
        "\n",
        "```python\n",
        "    def __init__(self, input_features):\n",
        "        super(Model, self).__init__()\n",
        "```\n",
        "这是类的构造函数 `__init__`，用于初始化模型对象。`super(Model, self).__init__()` 调用父类 `nn.Module` 的构造函数。\n",
        "\n",
        "```python\n",
        "        self.fc1 = nn.Linear(input_features, 5)\n",
        "        self.fc2 = nn.Linear(5, 4)\n",
        "        self.fc3 = nn.Linear(4, 3)\n",
        "        self.fc4 = nn.Linear(3, 1)\n",
        "```\n",
        "这几行代码定义了四个全连接层（fully connected layers），分别是：\n",
        "- `self.fc1`：输入特征数为 `input_features`，输出特征数为 5。\n",
        "- `self.fc2`：输入特征数为 5，输出特征数为 4。\n",
        "- `self.fc3`：输入特征数为 4，输出特征数为 3。\n",
        "- `self.fc4`：输入特征数为 3，输出特征数为 1。\n",
        "\n",
        "```python\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "```\n",
        "这两行代码定义了两个激活函数：\n",
        "- `self.sigmoid`：Sigmoid 激活函数。\n",
        "- `self.tanh`：Tanh 激活函数。\n",
        "\n",
        "```python\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.tanh(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "```\n",
        "这是 `forward` 方法，用于定义模型的前向传播过程。输入 `x` 依次通过各个全连接层和激活函数，最终输出 `out`。\n",
        "\n",
        "### 代码优化建议\n",
        "\n",
        "1. **激活函数选择**：在隐藏层中使用 Tanh 激活函数是可以的，但在输出层使用 Sigmoid 激活函数时，通常用于二分类问题。如果是回归问题，可能需要使用不同的激活函数或不使用激活函数。\n",
        "2. **模块化**：可以将重复的代码块合并，以减少代码行数。\n",
        "3. **类型注解**：可以添加类型注解，以提高代码的可读性和可维护性。\n",
        "\n",
        "优化后的代码如下：\n",
        "\n",
        "```python\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_features: int):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_features, 5)\n",
        "        self.fc2 = nn.Linear(5, 4)\n",
        "        self.fc3 = nn.Linear(4, 3)\n",
        "        self.fc4 = nn.Linear(3, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tanh(self.fc1(x))\n",
        "        x = self.tanh(self.fc2(x))\n",
        "        x = self.tanh(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "\n",
        "# 示例用法\n",
        "# model = Model(input_features=10)\n",
        "# x = torch.randn(1, 10)\n",
        "# output = model(x)\n",
        "```\n",
        "\n",
        "这样可以使代码更加简洁和易读，同时保持功能不变。如果你有特定的任务需求（例如分类或回归），可以根据需求调整激活函数。"
      ],
      "metadata": {
        "id": "GZ5Ln0FhU0oc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQc_zkmXgPA4"
      },
      "source": [
        "$H_{p}(q)=-\\frac{1}{N} \\sum_{i=1}^{N} y_{i} \\cdot \\log \\left(p\\left(y_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\cdot \\log \\left(1-p\\left(y_{i}\\right)\\right)$\n",
        "\n",
        "\n",
        "cost = -(Y * torch.log(hypothesis) + (1 - Y) * torch.log(1 - hypothesis)).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape[1]"
      ],
      "metadata": {
        "id": "5TW11CpaXI8p",
        "outputId": "20646171-8d4e-4d3b-ec19-867c7a567db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "dThQBzdegPA4"
      },
      "outputs": [],
      "source": [
        "# Create the network (an object of the Net class)\n",
        "net = Model(7,1)\n",
        "#In Binary Cross Entropy: the input and output should have the same shape\n",
        "#size_average = True --> the losses are averaged over observations for each minibatch\n",
        "# criterion = torch.nn.BCELoss(size_average=True)   #size_average=True 表示损失将对每个小批量中的观察值进行平均。需要注意的是，size_average 参数在较新的版本中已经被弃用，建议使用 reduction='mean'\n",
        "criterion = nn.BCELoss(size_average=True)\n",
        "# We will use SGD with momentum with a learning rate of 0.1\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9)#这行代码定义了一个使用动量的随机梯度下降（SGD）优化器 optimizer，学习率为 0.1，动量为 0.9。优化器将用于更新 net 模型的参数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "XluKsmnygPA4",
        "outputId": "487b76ea-8d06-4065-d2b3-8c89554d9985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 0.487, Accuracy: 0.781\n",
            "Epoch 2/200, Loss: 0.554, Accuracy: 0.656\n",
            "Epoch 3/200, Loss: 0.423, Accuracy: 0.781\n",
            "Epoch 4/200, Loss: 0.473, Accuracy: 0.781\n",
            "Epoch 5/200, Loss: 0.583, Accuracy: 0.750\n",
            "Epoch 6/200, Loss: 0.477, Accuracy: 0.812\n",
            "Epoch 7/200, Loss: 0.399, Accuracy: 0.906\n",
            "Epoch 8/200, Loss: 0.442, Accuracy: 0.719\n",
            "Epoch 9/200, Loss: 0.411, Accuracy: 0.844\n",
            "Epoch 10/200, Loss: 0.437, Accuracy: 0.750\n",
            "Epoch 11/200, Loss: 0.631, Accuracy: 0.688\n",
            "Epoch 12/200, Loss: 0.573, Accuracy: 0.688\n",
            "Epoch 13/200, Loss: 0.471, Accuracy: 0.781\n",
            "Epoch 14/200, Loss: 0.496, Accuracy: 0.781\n",
            "Epoch 15/200, Loss: 0.566, Accuracy: 0.750\n",
            "Epoch 16/200, Loss: 0.436, Accuracy: 0.750\n",
            "Epoch 17/200, Loss: 0.527, Accuracy: 0.750\n",
            "Epoch 18/200, Loss: 0.588, Accuracy: 0.750\n",
            "Epoch 19/200, Loss: 0.387, Accuracy: 0.844\n",
            "Epoch 20/200, Loss: 0.429, Accuracy: 0.812\n",
            "Epoch 21/200, Loss: 0.469, Accuracy: 0.781\n",
            "Epoch 22/200, Loss: 0.570, Accuracy: 0.719\n",
            "Epoch 23/200, Loss: 0.473, Accuracy: 0.750\n",
            "Epoch 24/200, Loss: 0.664, Accuracy: 0.719\n",
            "Epoch 25/200, Loss: 0.476, Accuracy: 0.688\n",
            "Epoch 26/200, Loss: 0.421, Accuracy: 0.844\n",
            "Epoch 27/200, Loss: 0.179, Accuracy: 0.906\n",
            "Epoch 28/200, Loss: 0.411, Accuracy: 0.812\n",
            "Epoch 29/200, Loss: 0.474, Accuracy: 0.812\n",
            "Epoch 30/200, Loss: 0.438, Accuracy: 0.812\n",
            "Epoch 31/200, Loss: 0.584, Accuracy: 0.688\n",
            "Epoch 32/200, Loss: 0.481, Accuracy: 0.750\n",
            "Epoch 33/200, Loss: 0.561, Accuracy: 0.625\n",
            "Epoch 34/200, Loss: 0.364, Accuracy: 0.875\n",
            "Epoch 35/200, Loss: 0.322, Accuracy: 0.812\n",
            "Epoch 36/200, Loss: 0.448, Accuracy: 0.781\n",
            "Epoch 37/200, Loss: 0.499, Accuracy: 0.719\n",
            "Epoch 38/200, Loss: 0.427, Accuracy: 0.781\n",
            "Epoch 39/200, Loss: 0.422, Accuracy: 0.875\n",
            "Epoch 40/200, Loss: 0.388, Accuracy: 0.781\n",
            "Epoch 41/200, Loss: 0.550, Accuracy: 0.688\n",
            "Epoch 42/200, Loss: 0.350, Accuracy: 0.906\n",
            "Epoch 43/200, Loss: 0.460, Accuracy: 0.750\n",
            "Epoch 44/200, Loss: 0.358, Accuracy: 0.844\n",
            "Epoch 45/200, Loss: 0.638, Accuracy: 0.719\n",
            "Epoch 46/200, Loss: 0.427, Accuracy: 0.781\n",
            "Epoch 47/200, Loss: 0.390, Accuracy: 0.844\n",
            "Epoch 48/200, Loss: 0.325, Accuracy: 0.812\n",
            "Epoch 49/200, Loss: 0.362, Accuracy: 0.750\n",
            "Epoch 50/200, Loss: 0.504, Accuracy: 0.781\n",
            "Epoch 51/200, Loss: 0.352, Accuracy: 0.812\n",
            "Epoch 52/200, Loss: 0.330, Accuracy: 0.875\n",
            "Epoch 53/200, Loss: 0.487, Accuracy: 0.719\n",
            "Epoch 54/200, Loss: 0.434, Accuracy: 0.750\n",
            "Epoch 55/200, Loss: 0.398, Accuracy: 0.750\n",
            "Epoch 56/200, Loss: 0.404, Accuracy: 0.750\n",
            "Epoch 57/200, Loss: 0.441, Accuracy: 0.719\n",
            "Epoch 58/200, Loss: 0.391, Accuracy: 0.844\n",
            "Epoch 59/200, Loss: 0.312, Accuracy: 0.844\n",
            "Epoch 60/200, Loss: 0.369, Accuracy: 0.844\n",
            "Epoch 61/200, Loss: 0.368, Accuracy: 0.781\n",
            "Epoch 62/200, Loss: 0.516, Accuracy: 0.750\n",
            "Epoch 63/200, Loss: 0.351, Accuracy: 0.875\n",
            "Epoch 64/200, Loss: 0.312, Accuracy: 0.844\n",
            "Epoch 65/200, Loss: 0.581, Accuracy: 0.688\n",
            "Epoch 66/200, Loss: 0.451, Accuracy: 0.688\n",
            "Epoch 67/200, Loss: 0.347, Accuracy: 0.844\n",
            "Epoch 68/200, Loss: 0.448, Accuracy: 0.781\n",
            "Epoch 69/200, Loss: 0.465, Accuracy: 0.688\n",
            "Epoch 70/200, Loss: 0.411, Accuracy: 0.719\n",
            "Epoch 71/200, Loss: 0.490, Accuracy: 0.781\n",
            "Epoch 72/200, Loss: 0.443, Accuracy: 0.750\n",
            "Epoch 73/200, Loss: 0.469, Accuracy: 0.719\n",
            "Epoch 74/200, Loss: 0.313, Accuracy: 0.875\n",
            "Epoch 75/200, Loss: 0.265, Accuracy: 0.875\n",
            "Epoch 76/200, Loss: 0.340, Accuracy: 0.812\n",
            "Epoch 77/200, Loss: 0.278, Accuracy: 0.906\n",
            "Epoch 78/200, Loss: 0.520, Accuracy: 0.750\n",
            "Epoch 79/200, Loss: 0.569, Accuracy: 0.750\n",
            "Epoch 80/200, Loss: 0.415, Accuracy: 0.812\n",
            "Epoch 81/200, Loss: 0.461, Accuracy: 0.750\n",
            "Epoch 82/200, Loss: 0.427, Accuracy: 0.750\n",
            "Epoch 83/200, Loss: 0.285, Accuracy: 0.906\n",
            "Epoch 84/200, Loss: 0.436, Accuracy: 0.812\n",
            "Epoch 85/200, Loss: 0.374, Accuracy: 0.875\n",
            "Epoch 86/200, Loss: 0.342, Accuracy: 0.875\n",
            "Epoch 87/200, Loss: 0.391, Accuracy: 0.750\n",
            "Epoch 88/200, Loss: 0.379, Accuracy: 0.875\n",
            "Epoch 89/200, Loss: 0.364, Accuracy: 0.875\n",
            "Epoch 90/200, Loss: 0.495, Accuracy: 0.750\n",
            "Epoch 91/200, Loss: 0.425, Accuracy: 0.844\n",
            "Epoch 92/200, Loss: 0.470, Accuracy: 0.719\n",
            "Epoch 93/200, Loss: 0.373, Accuracy: 0.875\n",
            "Epoch 94/200, Loss: 0.388, Accuracy: 0.844\n",
            "Epoch 95/200, Loss: 0.495, Accuracy: 0.844\n",
            "Epoch 96/200, Loss: 0.349, Accuracy: 0.844\n",
            "Epoch 97/200, Loss: 0.358, Accuracy: 0.844\n",
            "Epoch 98/200, Loss: 0.437, Accuracy: 0.750\n",
            "Epoch 99/200, Loss: 0.538, Accuracy: 0.688\n",
            "Epoch 100/200, Loss: 0.333, Accuracy: 0.844\n",
            "Epoch 101/200, Loss: 0.410, Accuracy: 0.750\n",
            "Epoch 102/200, Loss: 0.339, Accuracy: 0.906\n",
            "Epoch 103/200, Loss: 0.349, Accuracy: 0.781\n",
            "Epoch 104/200, Loss: 0.342, Accuracy: 0.781\n",
            "Epoch 105/200, Loss: 0.510, Accuracy: 0.719\n",
            "Epoch 106/200, Loss: 0.340, Accuracy: 0.812\n",
            "Epoch 107/200, Loss: 0.404, Accuracy: 0.781\n",
            "Epoch 108/200, Loss: 0.480, Accuracy: 0.688\n",
            "Epoch 109/200, Loss: 0.314, Accuracy: 0.875\n",
            "Epoch 110/200, Loss: 0.317, Accuracy: 0.812\n",
            "Epoch 111/200, Loss: 0.300, Accuracy: 0.938\n",
            "Epoch 112/200, Loss: 0.429, Accuracy: 0.750\n",
            "Epoch 113/200, Loss: 0.368, Accuracy: 0.812\n",
            "Epoch 114/200, Loss: 0.575, Accuracy: 0.781\n",
            "Epoch 115/200, Loss: 0.325, Accuracy: 0.875\n",
            "Epoch 116/200, Loss: 0.471, Accuracy: 0.781\n",
            "Epoch 117/200, Loss: 0.329, Accuracy: 0.844\n",
            "Epoch 118/200, Loss: 0.442, Accuracy: 0.750\n",
            "Epoch 119/200, Loss: 0.512, Accuracy: 0.750\n",
            "Epoch 120/200, Loss: 0.446, Accuracy: 0.750\n",
            "Epoch 121/200, Loss: 0.598, Accuracy: 0.781\n",
            "Epoch 122/200, Loss: 0.397, Accuracy: 0.844\n",
            "Epoch 123/200, Loss: 0.522, Accuracy: 0.844\n",
            "Epoch 124/200, Loss: 0.422, Accuracy: 0.781\n",
            "Epoch 125/200, Loss: 0.443, Accuracy: 0.844\n",
            "Epoch 126/200, Loss: 0.558, Accuracy: 0.812\n",
            "Epoch 127/200, Loss: 0.367, Accuracy: 0.750\n",
            "Epoch 128/200, Loss: 0.550, Accuracy: 0.781\n",
            "Epoch 129/200, Loss: 0.416, Accuracy: 0.812\n",
            "Epoch 130/200, Loss: 0.400, Accuracy: 0.812\n",
            "Epoch 131/200, Loss: 0.613, Accuracy: 0.656\n",
            "Epoch 132/200, Loss: 0.466, Accuracy: 0.688\n",
            "Epoch 133/200, Loss: 0.324, Accuracy: 0.844\n",
            "Epoch 134/200, Loss: 0.279, Accuracy: 0.844\n",
            "Epoch 135/200, Loss: 0.426, Accuracy: 0.781\n",
            "Epoch 136/200, Loss: 0.543, Accuracy: 0.750\n",
            "Epoch 137/200, Loss: 0.414, Accuracy: 0.781\n",
            "Epoch 138/200, Loss: 0.386, Accuracy: 0.781\n",
            "Epoch 139/200, Loss: 0.486, Accuracy: 0.719\n",
            "Epoch 140/200, Loss: 0.449, Accuracy: 0.812\n",
            "Epoch 141/200, Loss: 0.327, Accuracy: 0.875\n",
            "Epoch 142/200, Loss: 0.407, Accuracy: 0.812\n",
            "Epoch 143/200, Loss: 0.585, Accuracy: 0.656\n",
            "Epoch 144/200, Loss: 0.355, Accuracy: 0.875\n",
            "Epoch 145/200, Loss: 0.340, Accuracy: 0.812\n",
            "Epoch 146/200, Loss: 0.341, Accuracy: 0.844\n",
            "Epoch 147/200, Loss: 0.484, Accuracy: 0.719\n",
            "Epoch 148/200, Loss: 0.470, Accuracy: 0.750\n",
            "Epoch 149/200, Loss: 0.301, Accuracy: 0.812\n",
            "Epoch 150/200, Loss: 0.399, Accuracy: 0.844\n",
            "Epoch 151/200, Loss: 0.558, Accuracy: 0.688\n",
            "Epoch 152/200, Loss: 0.386, Accuracy: 0.812\n",
            "Epoch 153/200, Loss: 0.458, Accuracy: 0.750\n",
            "Epoch 154/200, Loss: 0.331, Accuracy: 0.812\n",
            "Epoch 155/200, Loss: 0.294, Accuracy: 0.875\n",
            "Epoch 156/200, Loss: 0.333, Accuracy: 0.812\n",
            "Epoch 157/200, Loss: 0.434, Accuracy: 0.812\n",
            "Epoch 158/200, Loss: 0.312, Accuracy: 0.781\n",
            "Epoch 159/200, Loss: 0.341, Accuracy: 0.812\n",
            "Epoch 160/200, Loss: 0.380, Accuracy: 0.875\n",
            "Epoch 161/200, Loss: 0.384, Accuracy: 0.906\n",
            "Epoch 162/200, Loss: 0.316, Accuracy: 0.844\n",
            "Epoch 163/200, Loss: 0.360, Accuracy: 0.844\n",
            "Epoch 164/200, Loss: 0.363, Accuracy: 0.844\n",
            "Epoch 165/200, Loss: 0.469, Accuracy: 0.719\n",
            "Epoch 166/200, Loss: 0.330, Accuracy: 0.844\n",
            "Epoch 167/200, Loss: 0.352, Accuracy: 0.875\n",
            "Epoch 168/200, Loss: 0.616, Accuracy: 0.656\n",
            "Epoch 169/200, Loss: 0.301, Accuracy: 0.875\n",
            "Epoch 170/200, Loss: 0.456, Accuracy: 0.781\n",
            "Epoch 171/200, Loss: 0.274, Accuracy: 0.875\n",
            "Epoch 172/200, Loss: 0.292, Accuracy: 0.875\n",
            "Epoch 173/200, Loss: 0.437, Accuracy: 0.844\n",
            "Epoch 174/200, Loss: 0.393, Accuracy: 0.781\n",
            "Epoch 175/200, Loss: 0.362, Accuracy: 0.875\n",
            "Epoch 176/200, Loss: 0.284, Accuracy: 0.875\n",
            "Epoch 177/200, Loss: 0.376, Accuracy: 0.781\n",
            "Epoch 178/200, Loss: 0.526, Accuracy: 0.656\n",
            "Epoch 179/200, Loss: 0.476, Accuracy: 0.781\n",
            "Epoch 180/200, Loss: 0.481, Accuracy: 0.781\n",
            "Epoch 181/200, Loss: 0.453, Accuracy: 0.750\n",
            "Epoch 182/200, Loss: 0.305, Accuracy: 0.875\n",
            "Epoch 183/200, Loss: 0.378, Accuracy: 0.781\n",
            "Epoch 184/200, Loss: 0.427, Accuracy: 0.812\n",
            "Epoch 185/200, Loss: 0.371, Accuracy: 0.844\n",
            "Epoch 186/200, Loss: 0.542, Accuracy: 0.656\n",
            "Epoch 187/200, Loss: 0.481, Accuracy: 0.906\n",
            "Epoch 188/200, Loss: 0.375, Accuracy: 0.844\n",
            "Epoch 189/200, Loss: 0.580, Accuracy: 0.656\n",
            "Epoch 190/200, Loss: 0.341, Accuracy: 0.844\n",
            "Epoch 191/200, Loss: 0.352, Accuracy: 0.812\n",
            "Epoch 192/200, Loss: 0.228, Accuracy: 0.938\n",
            "Epoch 193/200, Loss: 0.327, Accuracy: 0.781\n",
            "Epoch 194/200, Loss: 0.492, Accuracy: 0.812\n",
            "Epoch 195/200, Loss: 0.420, Accuracy: 0.781\n",
            "Epoch 196/200, Loss: 0.610, Accuracy: 0.719\n",
            "Epoch 197/200, Loss: 0.360, Accuracy: 0.844\n",
            "Epoch 198/200, Loss: 0.337, Accuracy: 0.844\n",
            "Epoch 199/200, Loss: 0.278, Accuracy: 0.844\n",
            "Epoch 200/200, Loss: 0.312, Accuracy: 0.844\n"
          ]
        }
      ],
      "source": [
        "# Train the network\n",
        "num_epochs = 200\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs,labels in train_loader:\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.float()\n",
        "        # Feed Forward\n",
        "        output = net(inputs)\n",
        "        # Loss Calculation\n",
        "        loss = criterion(output, labels)\n",
        "        # Clear the gradient buffer (we don't want to accumulate gradients)\n",
        "        optimizer.zero_grad() #这行代码清除优化器的梯度缓存，以防止梯度累积\n",
        "        # Backpropagation\n",
        "        loss.backward() #这行代码执行反向传播，计算梯度。每次反向传播之前调用 optimizer.zero_grad() 可以确保每次参数更新只使用当前批次的梯度，从而保证梯度计算的正确性\n",
        "        # Weight Update: w <-- w - lr * gradient\n",
        "        optimizer.step()\n",
        "\n",
        "    #Accuracy\n",
        "    # Since we are using a sigmoid, we will need to perform some thresholding\n",
        "    output = (output>0.5).float()\n",
        "    # Accuracy: (output == labels).float().sum() / output.shape[0]\n",
        "    accuracy = (output == labels).float().mean()\n",
        "    # Print statistics\n",
        "    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 解释 `optimizer.zero_grad()`\n",
        "\n",
        "在 PyTorch 中，梯度是通过反向传播计算的，并且默认情况下，梯度会累积（即相加）在每次调用 `backward()` 时。这意味着如果不清除之前的梯度，新的梯度会与之前的梯度相加，从而导致梯度值不正确。\n",
        "\n",
        "#### 为什么需要清除梯度缓存？\n",
        "\n",
        "在训练神经网络的过程中，每次更新模型参数时，我们希望使用当前批次数据计算的梯度来更新参数，而不是累积之前批次的梯度。因此，在每次反向传播之前，我们需要清除之前计算的梯度，以确保每次参数更新只使用当前批次的梯度。\n",
        "\n",
        "### 具体步骤\n",
        "\n",
        "1. **前向传播**：计算模型的输出。\n",
        "2. **计算损失**：根据模型的输出和真实标签计算损失。\n",
        "3. **清除梯度缓存**：调用 `optimizer.zero_grad()` 清除之前计算的梯度。\n",
        "4. **反向传播**：调用 `loss.backward()` 计算当前批次的梯度。\n",
        "5. **更新参数**：调用 `optimizer.step()` 根据计算的梯度更新模型参数。\n",
        "\n",
        "### 总结\n",
        "\n",
        "`optimizer.zero_grad()` 的作用是清除优化器的梯度缓存，以防止梯度累积。每次反向传播之前调用 `optimizer.zero_grad()` 可以确保每次参数更新只使用当前批次的梯度，从而保证梯度计算的正确性。"
      ],
      "metadata": {
        "id": "33zl2QQRho10"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "X34s6ePMgPA4"
      },
      "outputs": [],
      "source": [
        "aa = torch.tensor([3,4,5])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa"
      ],
      "metadata": {
        "id": "kXF1o3N5fANc",
        "outputId": "dac62ef6-5adb-4b26-e73a-6ce553ab8d72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa>3"
      ],
      "metadata": {
        "id": "-hIx_vZVfAlb",
        "outputId": "d2a26397-a5d5-4ab4-d5f4-7e7b6fc9eaaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bb =  torch.tensor([3,1,5])"
      ],
      "metadata": {
        "id": "LX5UghxgfBYb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa==bb"
      ],
      "metadata": {
        "id": "M8gXkYajf9fi",
        "outputId": "b00281f5-842f-4765-d738-ade1ec44a401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4uRQ9TRf-rH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}